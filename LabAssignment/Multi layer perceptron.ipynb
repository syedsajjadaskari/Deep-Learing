{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "d8d96a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "57cbc92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset(name= 'iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "ce5f2dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "589105e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2) (4, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1],\n",
    "    [0, 0]\n",
    "])\n",
    "\n",
    "# The labels for the training data.\n",
    "y = np.array([\n",
    "    [0],\n",
    "    [1],\n",
    "    [1],\n",
    "    [0]\n",
    "])\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "f742ca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, epochs, learning_rate, input_layer,hidden_layer,output_layer, reg_param = 0,m=4):\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.input_layer = input_layer\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self.output_layer = output_layer\n",
    "        self.reg_param = reg_param \n",
    "        self.m = m\n",
    "        self.W1 = np.random.normal(0,1,(hidden_layer,input_layer))\n",
    "        self.W2 = np.random.normal(0,1,(output_layer,hidden_layer))\n",
    "        self.B1 = np.random.random((hidden_layer, 1)) # 2x1\n",
    "        self.B2 = np.random.random((output_layer, 1)) # 1x1\n",
    "        self.cost = np.zeros((self.epochs, 1))\n",
    "\n",
    "    \n",
    "    #Activation function\n",
    "    def sigmoid(self, z, derv=False):\n",
    "        if derv: return z * (1 - z)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    def forward(self, x, predict=False):\n",
    "        a1 = x.reshape(x.shape[0], 1) # Getting the training example as a column vector.\n",
    "\n",
    "        z2 = self.W1.dot(a1) + self.B1 # 2x2 * 2x1 + 2x1 = 2x1\n",
    "        a2 = self.sigmoid(z2) # 2x1\n",
    "\n",
    "        z3 = self.W2.dot(a2) + self.B2 # 1x2 * 2x1 + 1x1 = 1x1\n",
    "        a3 = sigmoid(z3)\n",
    "\n",
    "        if predict: return a3\n",
    "        return (a1, a2, a3)\n",
    "    def train(self): # The arguments are to bypass UnboundLocalError error\n",
    "        for i in range(self.epochs):\n",
    "            c = 0\n",
    "            \n",
    "        \n",
    "            dW1 = 0\n",
    "            dW2 = 0\n",
    "\n",
    "            dB1 = 0\n",
    "            dB2 = 0\n",
    "        \n",
    "            for j in range(self.m):\n",
    "                print(\"\\rIteration: {} and {}\".format(i + 1, j + 1))\n",
    "\n",
    "            # Forward Prop.\n",
    "                a0 = X[j].reshape(X[j].shape[0], 1) # 2x1\n",
    "\n",
    "                z1 = self.W1.dot(a0) + self.B1 # 2x2 * 2x1 + 2x1 = 2x1\n",
    "                a1 = self.sigmoid(z1) # 2x1\n",
    "\n",
    "                z2 = self.W2.dot(a1) + self.B2 # 1x2 * 2x1 + 1x1 = 1x1\n",
    "                a2 = self.sigmoid(z2) # 1x1\n",
    "\n",
    "                # Back prop.\n",
    "                dz2 = a2 - y[j] # 1x1\n",
    "                dW2 += dz2 * a1.T # 1x1 .* 1x2 = 1x2\n",
    "\n",
    "                dz1 = np.multiply((self.W2.T * dz2), self.sigmoid(a1, derv=True)) # (2x1 * 1x1) .* 2x1 = 2x1\n",
    "                dW1 += dz1.dot(a0.T) # 2x1 * 1x2 = 2x2\n",
    "\n",
    "                dB1 += dz1 # 2x1\n",
    "                dB2 += dz2 # 1x1\n",
    "\n",
    "                c = c + (-(y[j] * np.log(a2)) - ((1 - y[j]) * np.log(1 - a2)))\n",
    "            sys.stdout.flush() # Updating the text.\n",
    "            \n",
    "            self.W1 = self.W1 - self.learning_rate * (dW1 / self.m) + ( (self.reg_param / self.m) * self.W1)\n",
    "            self.W2 = self.W2 - self.learning_rate * (dW2 / self.m) + ( (self.reg_param / self.m) * self.W2)\n",
    "\n",
    "            self.B1 = self.B1 - self.learning_rate * (dB1 / self.m)\n",
    "            self.B2 = self.B2 - self.learning_rate * (dB2 / self.m)\n",
    "            self.cost[i] = (c / self.m) + ( \n",
    "            (self.reg_param / (2 * self.m)) * \n",
    "            (\n",
    "                np.sum(np.power(self.W1, 2)) + \n",
    "                np.sum(np.power(self.W2, 2))\n",
    "            )\n",
    "            )\n",
    "        return (self.W1, self.W2, self.B1, self.B2)\n",
    "    def predict(self):\n",
    "        # Assigning the axes to the different elements.\n",
    "        plt.plot(range(self.epochs),self. cost)\n",
    "\n",
    "        # Labelling the x axis as the iterations axis.\n",
    "        plt.xlabel(\"Iterations\")\n",
    "\n",
    "    # Labelling the y axis as the cost axis.\n",
    "        plt.ylabel(\"Cost\")\n",
    "\n",
    "        # Showing the plot.\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "e51c0d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, epochs, learning_rate, input_layer,hidden_layer,output_layer, reg_param = 0,m=4):\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.input_layer = input_layer\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self.output_layer = output_layer\n",
    "        self.reg_param = reg_param \n",
    "        self.m = m\n",
    "        self.W1 = np.random.normal(0,1,(hidden_layer,input_layer))\n",
    "        self.W2 = np.random.normal(0,1,(output_layer,hidden_layer))\n",
    "        self.B1 = np.random.random((hidden_layer, 1)) # 2x1\n",
    "        self.B2 = np.random.random((output_layer, 1)) # 1x1\n",
    "        self.cost = np.zeros((self.epochs, 1))\n",
    "\n",
    "    \n",
    "    #Activation function\n",
    "    def sigmoid(self, z, derv=False):\n",
    "        if derv: return z * (1 - z)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    def forward(self, x, predict=False):\n",
    "        a1 = x.reshape(x.shape[0], 1) # Getting the training example as a column vector.\n",
    "\n",
    "        z2 = self.W1.dot(a1) + self.B1 # 2x2 * 2x1 + 2x1 = 2x1\n",
    "        a2 = self.sigmoid(z2) # 2x1\n",
    "\n",
    "        z3 = self.W2.dot(a2) + self.B2 # 1x2 * 2x1 + 1x1 = 1x1\n",
    "        a3 = sigmoid(z3)\n",
    "\n",
    "        if predict: return a3\n",
    "        return (a1, a2, a3)\n",
    "    def fit(self): # The arguments are to bypass UnboundLocalError error\n",
    "        for i in range(self.epochs):\n",
    "            c = 0\n",
    "            \n",
    "        \n",
    "            dW1 = 0\n",
    "            dW2 = 0\n",
    "\n",
    "            dB1 = 0\n",
    "            dB2 = 0\n",
    "        \n",
    "            for j in range(self.m):\n",
    "                print(\"\\rIteration: {} and {}\".format(i + 1, j + 1))\n",
    "\n",
    "            # Forward Prop.\n",
    "                a0 = X[j].reshape(X[j].shape[0], 1) # 2x1\n",
    "\n",
    "                z1 = self.W1.dot(a0) + self.B1 # 2x2 * 2x1 + 2x1 = 2x1\n",
    "                a1 = self.sigmoid(z1) # 2x1\n",
    "\n",
    "                z2 = self.W2.dot(a1) + self.B2 # 1x2 * 2x1 + 1x1 = 1x1\n",
    "                a2 = self.sigmoid(z2) # 1x1\n",
    "\n",
    "                # Back prop.\n",
    "                dz2 = a2 - y[j] # 1x1\n",
    "                dW2 += dz2 * a1.T # 1x1 .* 1x2 = 1x2\n",
    "\n",
    "                dz1 = np.multiply((self.W2.T * dz2), self.sigmoid(a1, derv=True)) # (2x1 * 1x1) .* 2x1 = 2x1\n",
    "                dW1 += dz1.dot(a0.T) # 2x1 * 1x2 = 2x2\n",
    "\n",
    "                dB1 += dz1 # 2x1\n",
    "                dB2 += dz2 # 1x1\n",
    "\n",
    "                c = c + (-(y[j] * np.log(a2)) - ((1 - y[j]) * np.log(1 - a2)))\n",
    "            sys.stdout.flush() # Updating the text.\n",
    "            \n",
    "            self.W1 = self.W1 - self.learning_rate * (dW1 / self.m) + ( (self.reg_param / self.m) * self.W1)\n",
    "            self.W2 = self.W2 - self.learning_rate * (dW2 / self.m) + ( (self.reg_param / self.m) * self.W2)\n",
    "\n",
    "            self.B1 = self.B1 - self.learning_rate * (dB1 / self.m)\n",
    "            self.B2 = self.B2 - self.learning_rate * (dB2 / self.m)\n",
    "            self.cost[i] = (c / self.m) + ( \n",
    "            (self.reg_param / (2 * self.m)) * \n",
    "            (\n",
    "                np.sum(np.power(self.W1, 2)) + \n",
    "                np.sum(np.power(self.W2, 2))\n",
    "            )\n",
    "            )\n",
    "        return (self.W1, self.W2, self.B1, self.B2)\n",
    "    def predict(self):\n",
    "        # Assigning the axes to the different elements.\n",
    "        plt.plot(range(self.epochs),self. cost)\n",
    "\n",
    "        # Labelling the x axis as the iterations axis.\n",
    "        plt.xlabel(\"Iterations\")\n",
    "\n",
    "    # Labelling the y axis as the cost axis.\n",
    "        plt.ylabel(\"Cost\")\n",
    "\n",
    "        # Showing the plot.\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "c5295b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(100,0.01,2,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "1c58f4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 and 1\n",
      "Iteration: 1 and 2\n",
      "Iteration: 1 and 3\n",
      "Iteration: 1 and 4\n",
      "Iteration: 2 and 1\n",
      "Iteration: 2 and 2\n",
      "Iteration: 2 and 3\n",
      "Iteration: 2 and 4\n",
      "Iteration: 3 and 1\n",
      "Iteration: 3 and 2\n",
      "Iteration: 3 and 3\n",
      "Iteration: 3 and 4\n",
      "Iteration: 4 and 1\n",
      "Iteration: 4 and 2\n",
      "Iteration: 4 and 3\n",
      "Iteration: 4 and 4\n",
      "Iteration: 5 and 1\n",
      "Iteration: 5 and 2\n",
      "Iteration: 5 and 3\n",
      "Iteration: 5 and 4\n",
      "Iteration: 6 and 1\n",
      "Iteration: 6 and 2\n",
      "Iteration: 6 and 3\n",
      "Iteration: 6 and 4\n",
      "Iteration: 7 and 1\n",
      "Iteration: 7 and 2\n",
      "Iteration: 7 and 3\n",
      "Iteration: 7 and 4\n",
      "Iteration: 8 and 1\n",
      "Iteration: 8 and 2\n",
      "Iteration: 8 and 3\n",
      "Iteration: 8 and 4\n",
      "Iteration: 9 and 1\n",
      "Iteration: 9 and 2\n",
      "Iteration: 9 and 3\n",
      "Iteration: 9 and 4\n",
      "Iteration: 10 and 1\n",
      "Iteration: 10 and 2\n",
      "Iteration: 10 and 3\n",
      "Iteration: 10 and 4\n",
      "Iteration: 11 and 1\n",
      "Iteration: 11 and 2\n",
      "Iteration: 11 and 3\n",
      "Iteration: 11 and 4\n",
      "Iteration: 12 and 1\n",
      "Iteration: 12 and 2\n",
      "Iteration: 12 and 3\n",
      "Iteration: 12 and 4\n",
      "Iteration: 13 and 1\n",
      "Iteration: 13 and 2\n",
      "Iteration: 13 and 3\n",
      "Iteration: 13 and 4\n",
      "Iteration: 14 and 1\n",
      "Iteration: 14 and 2\n",
      "Iteration: 14 and 3\n",
      "Iteration: 14 and 4\n",
      "Iteration: 15 and 1\n",
      "Iteration: 15 and 2\n",
      "Iteration: 15 and 3\n",
      "Iteration: 15 and 4\n",
      "Iteration: 16 and 1\n",
      "Iteration: 16 and 2\n",
      "Iteration: 16 and 3\n",
      "Iteration: 16 and 4\n",
      "Iteration: 17 and 1\n",
      "Iteration: 17 and 2\n",
      "Iteration: 17 and 3\n",
      "Iteration: 17 and 4\n",
      "Iteration: 18 and 1\n",
      "Iteration: 18 and 2\n",
      "Iteration: 18 and 3\n",
      "Iteration: 18 and 4\n",
      "Iteration: 19 and 1\n",
      "Iteration: 19 and 2\n",
      "Iteration: 19 and 3\n",
      "Iteration: 19 and 4\n",
      "Iteration: 20 and 1\n",
      "Iteration: 20 and 2\n",
      "Iteration: 20 and 3\n",
      "Iteration: 20 and 4\n",
      "Iteration: 21 and 1\n",
      "Iteration: 21 and 2\n",
      "Iteration: 21 and 3\n",
      "Iteration: 21 and 4\n",
      "Iteration: 22 and 1\n",
      "Iteration: 22 and 2\n",
      "Iteration: 22 and 3\n",
      "Iteration: 22 and 4\n",
      "Iteration: 23 and 1\n",
      "Iteration: 23 and 2\n",
      "Iteration: 23 and 3\n",
      "Iteration: 23 and 4\n",
      "Iteration: 24 and 1\n",
      "Iteration: 24 and 2\n",
      "Iteration: 24 and 3\n",
      "Iteration: 24 and 4\n",
      "Iteration: 25 and 1\n",
      "Iteration: 25 and 2\n",
      "Iteration: 25 and 3\n",
      "Iteration: 25 and 4\n",
      "Iteration: 26 and 1\n",
      "Iteration: 26 and 2\n",
      "Iteration: 26 and 3\n",
      "Iteration: 26 and 4\n",
      "Iteration: 27 and 1\n",
      "Iteration: 27 and 2\n",
      "Iteration: 27 and 3\n",
      "Iteration: 27 and 4\n",
      "Iteration: 28 and 1\n",
      "Iteration: 28 and 2\n",
      "Iteration: 28 and 3\n",
      "Iteration: 28 and 4\n",
      "Iteration: 29 and 1\n",
      "Iteration: 29 and 2\n",
      "Iteration: 29 and 3\n",
      "Iteration: 29 and 4\n",
      "Iteration: 30 and 1\n",
      "Iteration: 30 and 2\n",
      "Iteration: 30 and 3\n",
      "Iteration: 30 and 4\n",
      "Iteration: 31 and 1\n",
      "Iteration: 31 and 2\n",
      "Iteration: 31 and 3\n",
      "Iteration: 31 and 4\n",
      "Iteration: 32 and 1\n",
      "Iteration: 32 and 2\n",
      "Iteration: 32 and 3\n",
      "Iteration: 32 and 4\n",
      "Iteration: 33 and 1\n",
      "Iteration: 33 and 2\n",
      "Iteration: 33 and 3\n",
      "Iteration: 33 and 4\n",
      "Iteration: 34 and 1\n",
      "Iteration: 34 and 2\n",
      "Iteration: 34 and 3\n",
      "Iteration: 34 and 4\n",
      "Iteration: 35 and 1\n",
      "Iteration: 35 and 2\n",
      "Iteration: 35 and 3\n",
      "Iteration: 35 and 4\n",
      "Iteration: 36 and 1\n",
      "Iteration: 36 and 2\n",
      "Iteration: 36 and 3\n",
      "Iteration: 36 and 4\n",
      "Iteration: 37 and 1\n",
      "Iteration: 37 and 2\n",
      "Iteration: 37 and 3\n",
      "Iteration: 37 and 4\n",
      "Iteration: 38 and 1\n",
      "Iteration: 38 and 2\n",
      "Iteration: 38 and 3\n",
      "Iteration: 38 and 4\n",
      "Iteration: 39 and 1\n",
      "Iteration: 39 and 2\n",
      "Iteration: 39 and 3\n",
      "Iteration: 39 and 4\n",
      "Iteration: 40 and 1\n",
      "Iteration: 40 and 2\n",
      "Iteration: 40 and 3\n",
      "Iteration: 40 and 4\n",
      "Iteration: 41 and 1\n",
      "Iteration: 41 and 2\n",
      "Iteration: 41 and 3\n",
      "Iteration: 41 and 4\n",
      "Iteration: 42 and 1\n",
      "Iteration: 42 and 2\n",
      "Iteration: 42 and 3\n",
      "Iteration: 42 and 4\n",
      "Iteration: 43 and 1\n",
      "Iteration: 43 and 2\n",
      "Iteration: 43 and 3\n",
      "Iteration: 43 and 4\n",
      "Iteration: 44 and 1\n",
      "Iteration: 44 and 2\n",
      "Iteration: 44 and 3\n",
      "Iteration: 44 and 4\n",
      "Iteration: 45 and 1\n",
      "Iteration: 45 and 2\n",
      "Iteration: 45 and 3\n",
      "Iteration: 45 and 4\n",
      "Iteration: 46 and 1\n",
      "Iteration: 46 and 2\n",
      "Iteration: 46 and 3\n",
      "Iteration: 46 and 4\n",
      "Iteration: 47 and 1\n",
      "Iteration: 47 and 2\n",
      "Iteration: 47 and 3\n",
      "Iteration: 47 and 4\n",
      "Iteration: 48 and 1\n",
      "Iteration: 48 and 2\n",
      "Iteration: 48 and 3\n",
      "Iteration: 48 and 4\n",
      "Iteration: 49 and 1\n",
      "Iteration: 49 and 2\n",
      "Iteration: 49 and 3\n",
      "Iteration: 49 and 4\n",
      "Iteration: 50 and 1\n",
      "Iteration: 50 and 2\n",
      "Iteration: 50 and 3\n",
      "Iteration: 50 and 4\n",
      "Iteration: 51 and 1\n",
      "Iteration: 51 and 2\n",
      "Iteration: 51 and 3\n",
      "Iteration: 51 and 4\n",
      "Iteration: 52 and 1\n",
      "Iteration: 52 and 2\n",
      "Iteration: 52 and 3\n",
      "Iteration: 52 and 4\n",
      "Iteration: 53 and 1\n",
      "Iteration: 53 and 2\n",
      "Iteration: 53 and 3\n",
      "Iteration: 53 and 4\n",
      "Iteration: 54 and 1\n",
      "Iteration: 54 and 2\n",
      "Iteration: 54 and 3\n",
      "Iteration: 54 and 4\n",
      "Iteration: 55 and 1\n",
      "Iteration: 55 and 2\n",
      "Iteration: 55 and 3\n",
      "Iteration: 55 and 4\n",
      "Iteration: 56 and 1\n",
      "Iteration: 56 and 2\n",
      "Iteration: 56 and 3\n",
      "Iteration: 56 and 4\n",
      "Iteration: 57 and 1\n",
      "Iteration: 57 and 2\n",
      "Iteration: 57 and 3\n",
      "Iteration: 57 and 4\n",
      "Iteration: 58 and 1\n",
      "Iteration: 58 and 2\n",
      "Iteration: 58 and 3\n",
      "Iteration: 58 and 4\n",
      "Iteration: 59 and 1\n",
      "Iteration: 59 and 2\n",
      "Iteration: 59 and 3\n",
      "Iteration: 59 and 4\n",
      "Iteration: 60 and 1\n",
      "Iteration: 60 and 2\n",
      "Iteration: 60 and 3\n",
      "Iteration: 60 and 4\n",
      "Iteration: 61 and 1\n",
      "Iteration: 61 and 2\n",
      "Iteration: 61 and 3\n",
      "Iteration: 61 and 4\n",
      "Iteration: 62 and 1\n",
      "Iteration: 62 and 2\n",
      "Iteration: 62 and 3\n",
      "Iteration: 62 and 4\n",
      "Iteration: 63 and 1\n",
      "Iteration: 63 and 2\n",
      "Iteration: 63 and 3\n",
      "Iteration: 63 and 4\n",
      "Iteration: 64 and 1\n",
      "Iteration: 64 and 2\n",
      "Iteration: 64 and 3\n",
      "Iteration: 64 and 4\n",
      "Iteration: 65 and 1\n",
      "Iteration: 65 and 2\n",
      "Iteration: 65 and 3\n",
      "Iteration: 65 and 4\n",
      "Iteration: 66 and 1\n",
      "Iteration: 66 and 2\n",
      "Iteration: 66 and 3\n",
      "Iteration: 66 and 4\n",
      "Iteration: 67 and 1\n",
      "Iteration: 67 and 2\n",
      "Iteration: 67 and 3\n",
      "Iteration: 67 and 4\n",
      "Iteration: 68 and 1\n",
      "Iteration: 68 and 2\n",
      "Iteration: 68 and 3\n",
      "Iteration: 68 and 4\n",
      "Iteration: 69 and 1\n",
      "Iteration: 69 and 2\n",
      "Iteration: 69 and 3\n",
      "Iteration: 69 and 4\n",
      "Iteration: 70 and 1\n",
      "Iteration: 70 and 2\n",
      "Iteration: 70 and 3\n",
      "Iteration: 70 and 4\n",
      "Iteration: 71 and 1\n",
      "Iteration: 71 and 2\n",
      "Iteration: 71 and 3\n",
      "Iteration: 71 and 4\n",
      "Iteration: 72 and 1\n",
      "Iteration: 72 and 2\n",
      "Iteration: 72 and 3\n",
      "Iteration: 72 and 4\n",
      "Iteration: 73 and 1\n",
      "Iteration: 73 and 2\n",
      "Iteration: 73 and 3\n",
      "Iteration: 73 and 4\n",
      "Iteration: 74 and 1\n",
      "Iteration: 74 and 2\n",
      "Iteration: 74 and 3\n",
      "Iteration: 74 and 4\n",
      "Iteration: 75 and 1\n",
      "Iteration: 75 and 2\n",
      "Iteration: 75 and 3\n",
      "Iteration: 75 and 4\n",
      "Iteration: 76 and 1\n",
      "Iteration: 76 and 2\n",
      "Iteration: 76 and 3\n",
      "Iteration: 76 and 4\n",
      "Iteration: 77 and 1\n",
      "Iteration: 77 and 2\n",
      "Iteration: 77 and 3\n",
      "Iteration: 77 and 4\n",
      "Iteration: 78 and 1\n",
      "Iteration: 78 and 2\n",
      "Iteration: 78 and 3\n",
      "Iteration: 78 and 4\n",
      "Iteration: 79 and 1\n",
      "Iteration: 79 and 2\n",
      "Iteration: 79 and 3\n",
      "Iteration: 79 and 4\n",
      "Iteration: 80 and 1\n",
      "Iteration: 80 and 2\n",
      "Iteration: 80 and 3\n",
      "Iteration: 80 and 4\n",
      "Iteration: 81 and 1\n",
      "Iteration: 81 and 2\n",
      "Iteration: 81 and 3\n",
      "Iteration: 81 and 4\n",
      "Iteration: 82 and 1\n",
      "Iteration: 82 and 2\n",
      "Iteration: 82 and 3\n",
      "Iteration: 82 and 4\n",
      "Iteration: 83 and 1\n",
      "Iteration: 83 and 2\n",
      "Iteration: 83 and 3\n",
      "Iteration: 83 and 4\n",
      "Iteration: 84 and 1\n",
      "Iteration: 84 and 2\n",
      "Iteration: 84 and 3\n",
      "Iteration: 84 and 4\n",
      "Iteration: 85 and 1\n",
      "Iteration: 85 and 2\n",
      "Iteration: 85 and 3\n",
      "Iteration: 85 and 4\n",
      "Iteration: 86 and 1\n",
      "Iteration: 86 and 2\n",
      "Iteration: 86 and 3\n",
      "Iteration: 86 and 4\n",
      "Iteration: 87 and 1\n",
      "Iteration: 87 and 2\n",
      "Iteration: 87 and 3\n",
      "Iteration: 87 and 4\n",
      "Iteration: 88 and 1\n",
      "Iteration: 88 and 2\n",
      "Iteration: 88 and 3\n",
      "Iteration: 88 and 4\n",
      "Iteration: 89 and 1\n",
      "Iteration: 89 and 2\n",
      "Iteration: 89 and 3\n",
      "Iteration: 89 and 4\n",
      "Iteration: 90 and 1\n",
      "Iteration: 90 and 2\n",
      "Iteration: 90 and 3\n",
      "Iteration: 90 and 4\n",
      "Iteration: 91 and 1\n",
      "Iteration: 91 and 2\n",
      "Iteration: 91 and 3\n",
      "Iteration: 91 and 4\n",
      "Iteration: 92 and 1\n",
      "Iteration: 92 and 2\n",
      "Iteration: 92 and 3\n",
      "Iteration: 92 and 4\n",
      "Iteration: 93 and 1\n",
      "Iteration: 93 and 2\n",
      "Iteration: 93 and 3\n",
      "Iteration: 93 and 4\n",
      "Iteration: 94 and 1\n",
      "Iteration: 94 and 2\n",
      "Iteration: 94 and 3\n",
      "Iteration: 94 and 4\n",
      "Iteration: 95 and 1\n",
      "Iteration: 95 and 2\n",
      "Iteration: 95 and 3\n",
      "Iteration: 95 and 4\n",
      "Iteration: 96 and 1\n",
      "Iteration: 96 and 2\n",
      "Iteration: 96 and 3\n",
      "Iteration: 96 and 4\n",
      "Iteration: 97 and 1\n",
      "Iteration: 97 and 2\n",
      "Iteration: 97 and 3\n",
      "Iteration: 97 and 4\n",
      "Iteration: 98 and 1\n",
      "Iteration: 98 and 2\n",
      "Iteration: 98 and 3\n",
      "Iteration: 98 and 4\n",
      "Iteration: 99 and 1\n",
      "Iteration: 99 and 2\n",
      "Iteration: 99 and 3\n",
      "Iteration: 99 and 4\n",
      "Iteration: 100 and 1\n",
      "Iteration: 100 and 2\n",
      "Iteration: 100 and 3\n",
      "Iteration: 100 and 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-1.19269532,  0.87863656],\n",
       "        [-0.70110573, -0.12656569]]),\n",
       " array([[-0.92923889, -0.25272881]]),\n",
       " array([[0.25867241],\n",
       "        [0.12361163]]),\n",
       " array([[0.14570286]]))"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "60149ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAGwCAYAAABSN5pGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABOu0lEQVR4nO3dd3RUZeLG8e/MJJMQSAFSCBAILdKRGkIQVFDsIIqAIMUKBqTYcBV1LaDyA5EiCBZQURBUBERQIoQWWihKDT20hBJSKKlzf3+wzm4CKIQkN+X5nDPnbO68M/PMe84yj7e812IYhoGIiIiIOFnNDiAiIiJS1KggiYiIiOSigiQiIiKSiwqSiIiISC4qSCIiIiK5qCCJiIiI5KKCJCIiIpKLi9kBiiuHw8Hx48fx9PTEYrGYHUdERESugWEYpKamUrlyZazWq+8nUkHKo+PHjxMUFGR2DBEREcmDI0eOULVq1as+r4KUR56ensClCfby8jI5jYiIiFyLlJQUgoKCnL/jV6OClEd/HVbz8vJSQRIRESlm/un0GJ2kLSIiIpKLCpKIiIhILipIIiIiIrmoIImIiIjkooIkIiIikosKkoiIiEguKkgiIiIiuaggiYiIiOSigiQiIiKSiwqSiIiISC4qSCIiIiK5qCCJiIiI5KKCVMQ4HAbLdiaYHUNERKRUU0EqQgzDYORP23nyy03839I9GIZhdiQREZFSSQWpCLFYLFSr4AHApOX7eHvRLpUkERERE6ggFTHPtK/FW50bAPD5moO8On87DodKkoiISGFSQSqC+oQF88HDjbFa4Jv1cbwwdxtZ2Q6zY4mIiJQaKkhF1CMtgvioR1NcrBZ+2HKMwd9uISNLJUlERKQwqCAVYfc3qcyU3s2x26z8sj2eZ77aRFpmttmxRERESjwVpCLujvoBfNavBe6uVpbvOUX/LzZyLj3L7FgiIiIlmgpSMXBLHT++fDyUcm4uRB84w2OfrSf5QqbZsUREREosFaRiolWNCsx6MhQfD1e2xCXRc/o6Tp9LNzuWiIhIiaSCVIw0CfJh9tOt8S3nxs4TKXT/JJoTyRfNjiUiIlLiqCAVM3UrefHdM62p7O3O/lPn6TY1msNnzpsdS0REpERRQSqGavqV47sBYQRX9ODo2Yt0mxrN3oRUs2OJiIiUGCpIxVTV8h58NyCMmwI8OZmaziOfRPPn0WSzY4mIiJQIKkjFmL+nO3OeaU2Tqt6cvZDJo9PXseFgotmxREREij0VpGLOx8PO10+GElqjAqnpWfT5fD0r9pw0O5aIiEixpoJUAni6uzLz8VbcdpMfaZkOnvpyE4v/PGF2LBERkWJLBamEcHe18cljLbi3cSCZ2QaDvtnM3E1HzI4lIiJSLKkglSB2FysTejSlR8sgHAa8OO8PPl990OxYIiIixY4KUgljs1oY3bURT7atAcBbi3YyflkshmGYnExERKT4UEEqgSwWC6/eW4/hd4QAMH7ZXt5etAuHQyVJRETkWqgglVAWi4XnOtThzfvrA/D5moO89P0fZGU7TE4mIiJS9KkglXD9wmswtlsTbFYL82KOMuibLaRnZZsdS0REpEhTQSoFHmpelY97NcNus7JkRzxPzNjE+fQss2OJiIgUWSpIpUSnBpWY0b8lHnYbq/edpten60m6kGF2LBERkSJJBakUaVPbl2+eao2PhytbjyTR/ZN1nExJMzuWiIhIkaOCVMrcHOTDd8+EEeDlxp6EVB6aupbDZ86bHUtERKRIUUEqhUICPJk3oA3VKnhwJPEiD0+NZnd8itmxREREigwVpFIqqIIH8waEUbeSJ6dS03lkajQxhxPNjiUiIlIkqCCVYv5e7sx5Oozm1cuTkpZFr0/Xs2LPSbNjiYiImE4FqZTz9nDlqyda0T7Ej7RMB099uYmF246bHUtERMRUKkiCh92F6X1a8ECTymRmGzw3ewtfrTtsdiwRERHTqCAJAHYXK+O738xjratjGDBy/nYmRO7VTW5FRKRUUkESJ6vVwludG/BchzoAjPstln8v3Kmb3IqISKmjgiQ5WCwWht8R4rzJ7Yy1hxj+3VYydZNbEREpRVSQ5Ir6hddgfPebcbFamL/1OE99uYkLGbp/m4iIlA4qSHJVXZpWYXrfFri7Wlmx5xS9df82EREpJVSQ5G/ddpM/s54Mxcvdhc1xSTzySTTxybp/m4iIlGwqSPKPmlevwNwBbQjwciM24RwPTVnL/lPnzI4lIiJSYFSQ5JrcVMmT7we2oaZvWY4lXaTb1Gi2HUkyO5aIiEiBUEGSa1a1vAdzB4TRuKo3iecz6Dl9Hav2njI7loiISL5TQZLrUrGcG9881Zq2tX25kJHN4zM2skC3JhERkRJGBUmuWzk3Fz7r14L7GgdeujXJt1v4Ys1Bs2OJiIjkGxUkyRM3FxsTejSlb1h1AP69cCdjlu7WrUlERKREUEGSPLNaLbz5QAOevyMEgMnL9zPi+z/J0qrbIiJSzKkgyQ2xWCwM7lCH0V0bYbXAnE1HGPD1Zi5mZJsdTUREJM9UkCRf9GxVjSm9m+PmYmXZrgQe+0yrbouISPGlgiT5plODSnz1xKVVtzcdPku3qdGcSL5odiwREZHrpoIk+apVjf+uur335Dm6fryWvQmpZscSERG5LipIku/+WnW7ll9ZTiSn8fDUaDYdSjQ7loiIyDVTQZICUbW8B/MGtKFZNR+SL2bS69P1/Loj3uxYIiIi10QFSQpM+bJ2Zj3Zmg51/UnPcjDg6xi+WR9ndiwREZF/pIIkBaqM3cYnjzWne4sgHAb868c/+fC3WC0oKSIiRZoKkhQ4F5uV9x5qxHO31wbgo8i9/OtHLSgpIiJFlwqSFAqLxcLwO2/i3QcbYrXAtxuOMODrGC0oKSIiRZIKkhSqXqHV/2dByZM8+uk6Es9rQUkRESlaTC9IkydPJjg4GHd3d0JDQ9mwYcPfjk9KSiIiIoLAwEDc3NwICQlh8eLFOcYcO3aM3r17U7FiRcqUKUOjRo3YtGmT8/l+/fphsVhyPO66664C+X5yuU4NKjHryVC8y7iyJS6Jh6eu5UjiBbNjiYiIOJlakObMmcPw4cN544032Lx5M02aNKFTp06cPHnyiuMzMjK44447OHToEPPmzWPPnj1Mnz6dKlWqOMecPXuW8PBwXF1d+eWXX9i5cydjx46lfPnyOd7rrrvu4sSJE87Ht99+W6DfVXJqEVyBeQPCqOztzoFT53nw47VsP5ZsdiwREREALIaJlxOFhobSsmVLJk2aBIDD4SAoKIjBgwczYsSIy8ZPnTqVMWPGsHv3blxdXa/4niNGjGDNmjWsWrXqqp/br18/kpKSmD9/fp6zp6Sk4O3tTXJyMl5eXnl+n9IuPjmNfl9sYHd8KmXtNqb0bk67ED+zY4mISAl1rb/fpu1BysjIICYmho4dO/43jNVKx44diY6OvuJrFixYQFhYGBEREQQEBNCwYUNGjRpFdnZ2jjEtWrSgW7du+Pv707RpU6ZPn37Ze61YsQJ/f39uuukmBg4cyJkzZ/42b3p6OikpKTkecuMqebvz3YAw2tSqyPmMbB6fsZHvY46aHUtEREo50wrS6dOnyc7OJiAgIMf2gIAA4uOvvOLygQMHmDdvHtnZ2SxevJiRI0cyduxY3nnnnRxjpkyZQp06dVi6dCkDBw7kueeeY+bMmc4xd911F19++SWRkZG8//77REVFcffdd+coWrmNHj0ab29v5yMoKOgGZ0D+4uXuyoz+reh8c2WyHAbPz93G5OX7tFaSiIiYxrRDbMePH6dKlSqsXbuWsLAw5/aXXnqJqKgo1q9ff9lrQkJCSEtL4+DBg9hsNgDGjRvHmDFjOHHiBAB2u50WLVqwdu1a5+uee+45Nm7ceNU9UwcOHKBWrVosW7aMDh06XHFMeno66enpzr9TUlIICgrSIbZ85HAYvL9kN5+sPABAr9Bq/PuBBrjYTL+WQERESogif4jN19cXm81GQkJCju0JCQlUqlTpiq8JDAwkJCTEWY4A6tWrR3x8PBkZGc4x9evXz/G6evXqERd39Vtc1KxZE19fX/bt23fVMW5ubnh5eeV4SP6yWi28ck893ry/PhYLzFofp7WSRETEFKYVJLvdTvPmzYmMjHRuczgcREZG5tij9L/Cw8PZt28fDsd/V2COjY0lMDAQu93uHLNnz54cr4uNjaV69epXzXL06FHOnDlDYGDgjXwlySf9wmswpVcz51pJPaev48y59H9+oYiISD4x9djF8OHDmT59OjNnzmTXrl0MHDiQ8+fP079/fwD69OnDK6+84hw/cOBAEhMTGTJkCLGxsfz888+MGjWKiIgI55hhw4axbt06Ro0axb59+/jmm2+YNm2ac8y5c+d48cUXWbduHYcOHSIyMpLOnTtTu3ZtOnXqVLgTIFd1V8NAZj0Zio+HK1uPJPHQlLUcOn3e7FgiIlJaGCabOHGiUa1aNcNutxutWrUy1q1b53yuffv2Rt++fXOMX7t2rREaGmq4ubkZNWvWNN59910jKysrx5iFCxcaDRs2NNzc3Iy6desa06ZNcz534cIF48477zT8/PwMV1dXo3r16sZTTz1lxMfHX1fu5ORkAzCSk5Ov/0vLNdubkGqEvxdpVH95kdH0rV+NzYcTzY4kIiLF2LX+fpu6DlJxpnWQCs/J1DSemLGJP48l4+5qZUKPptzZ4MrnqYmIiPydIn+Stsi18vd0Z/bTrbntJj/SMh0M+DqGL6MPmR1LRERKMBUkKRbKurkwvU8LerYKwmHA6z/tYPTiXTgc2gEqIiL5TwVJig0Xm5VRDzbihTtDAPhk5QEGz95CWqaWARARkfylgiTFisViYdDtdfiwexNcbRZ+/uMEj322nqQLGWZHExGREkQFSYqlB5tWZWb/Vni6u7Dx0Fm6TllL3JkLZscSEZESQgVJiq02tX2ZN6ANlb3dOXDqPF2nrGHrkSSzY4mISAmggiTF2k2VPPkxIpz6gV6cPpdBj2nR/Lrjyjc7FhERuVYqSFLsBXi5892AMG79zzIAz3wdwxdrDpodS0REijEVJCkRyrm58GmfFjwaWg3DgH8v3MlbC3eSrWUAREQkD1SQpMRwsVl5t0tDXr6rLgCfrznIs7NiuJihZQBEROT6qCBJiWKxWBh4ay0m9GyK3WZl6Y4EekyL5lRqutnRRESkGFFBkhLpgSaVmfVUKD4ermw7msyDH69hb0Kq2bFERKSYUEGSEqtlcAV+fDac4IoeHD17ka5T1rJ232mzY4mISDGggiQlWg3fsvzwbDjNq5cnNS2LPp9vYF7MUbNjiYhIEaeCJCVehbJ2Zj0Zyn2NA8lyGLwwdxvjft2DYegKNxERuTIVJCkV3F1tTOjRlIjbagEw4fd9DJ2zlfQsXeEmIiKXU0GSUsNqtfBip7p88FBjXKwWftp6nN6frufsed3oVkREclJBklLnkZZBzOjfCk+3Sze6ffDjNRw4dc7sWCIiUoSoIEmp1LaOL98/24YqPmU4dOYCXaesZf2BM2bHEhGRIkIFSUqtkABP5keEc3OQD0kXMun92Xp+2Kwr3ERERAVJSjk/TzdmP92aexpVIjPbYPh3usJNRERUkERwd7UxqWczBt763yvchszeSlqmrnATESmtVJBEuHSF28t31eX9hxrhYrWwYNtxHp2+jtPndA83EZHSSAVJ5H90b1mNLx9vhZe7C5vjknQPNxGRUkoFSSSXNrV9+eHZcKpX9OBI4qV7uK3ae8rsWCIiUohUkESuoLZ/OX58NpyWwZfu4dbvi418ve6w2bFERKSQqCCJXEWFsna+fjKUB5tWIdth8Nr87by1cCfZDl3hJiJS0qkgifwNNxcb4x5pwvN3hADw+ZqDPP3lJs6lZ5mcTERECpIKksg/sFgsDO5Qh0mPNsXNxUrk7pN0mxrNsaSLZkcTEZECooIkco3ua1yZ2U+3xrecnV0nUug8aQ1b4s6aHUtERAqACpLIdWharTzzI8KpW8mT0+fS6TFtHQu3HTc7loiI5DMVJJHrVLW8B/MGtqFDXX/SsxwM/nYL45fF6vYkIiIliAqSSB6Uc3NhWp8WPHVLDQDGL9vLc7o9iYhIiaGCJJJHNquFV++tz3tdL92eZOG24/SYto6TqWlmRxMRkRukgiRyg3q0qsaXT7TCu4wrW48k0WXSGnYcTzY7loiI3AAVJJF80KaWL/MjwqnpV5bjyWl0mxrNrzvizY4lIiJ5pIIkkk9q+Jblx2fDuaWOLxcysnnm6xg+XrFPJ2+LiBRDKkgi+ci7jCtf9GtJn7DqGAZ8sGQPz3+3TSdvi4gUMypIIvnMxWblrc4NebtLQ2xWCz9sOUbP6es4lZpudjQREblGKkgiBeSx1tWZ2b8VXu4ubIlLovOk1Tp5W0SkmFBBEilAbev85+Rt30snbz88JZol23XytohIUaeCJFLAavqV48dnw2lb25eLmdkM+DqGSb/v1cnbIiJFmAqSSCHw9nBlRv+W9GsTDMD//RrLEK28LSJSZKkgiRQSF5uVNx9owKgHL628vWDbcbp/Ek1CilbeFhEpalSQRArZo6HV+OqJUHw8XNl2NJkHJq1m25Eks2OJiMj/UEESMUFYrYosiGhLSEA5ElLS6fZJND9tPWZ2LBER+Q8VJBGTVKvowfcD29Cxnj8ZWQ6GzN7K+0t243Do5G0REbOpIImYyNPdlU8ea8HAW2sBMGXFfp7+ahOpaZkmJxMRKd1UkERMZrNaePmuuozvfjN2FyvLdp2k68drOXzmvNnRRERKLRUkkSKiS9MqfPdMGAFebuw9eY4HJq1hzb7TZscSESmVVJBEipCbg3xYMKgtTYJ8SL6YSZ/PN/DFmoNaVFJEpJCpIIkUMQFe7sx5ujVdm1Uh22Hw74U7GfH9n6RnaVFJEZHCooIkUgS5u9oY260Jr95TD6sF5mw6wqPT13MyVYtKiogUBhUkkSLKYrHwVLuafNG/FZ7uLsQcPkvnSWv442iS2dFEREo8FSSRIq59iB8/RYRT068sJ5LT6DZVi0qKiBQ0FSSRYqCmXznmR4Rz201+pP9nUcnRi3eRrUUlRUQKhAqSSDHh5e7Kp31bOheV/GTlAR6fsZHkC1pUUkQkv6kgiRQjfy0qObFnU9xdrUTFnqLz5NXsO5lqdjQRkRJFBUmkGLq/SWW+H9iGKj5lOHTmAl0mr+W3nQlmxxIRKTFUkESKqQaVvVkwKJzQGhU4l57FU19uYkLkXt3sVkQkH6ggiRRjFcu58fWTofQNqw7AuN9ieXbWZs6lZ5mcTESkeFNBEinmXG1W/t25IR881Bi7zcqSHfF0/XgNh07rZrciInmlgiRSQjzSMojZz7TG39ON2IRzPDBpNVGxp8yOJSJSLKkgiZQgzaqVZ+HgtjSt5kNKWhb9v9jAlBX7dbNbEZHrpIIkUsIEeLkz++nW9GgZhMOA95fsZtC3W7iQofOSRESulQqSSAnk5mJjdNdGvNOlIa42Cz//cYKuH68l7swFs6OJiBQLphekyZMnExwcjLu7O6GhoWzYsOFvxyclJREREUFgYCBubm6EhISwePHiHGOOHTtG7969qVixImXKlKFRo0Zs2rTJ+bxhGLz++usEBgZSpkwZOnbsyN69ewvk+4mYxWKx0Lt1db59qjW+5dzYHZ/K/ZNWs1LnJYmI/CNTC9KcOXMYPnw4b7zxBps3b6ZJkyZ06tSJkydPXnF8RkYGd9xxB4cOHWLevHns2bOH6dOnU6VKFeeYs2fPEh4ejqurK7/88gs7d+5k7NixlC9f3jnmgw8+YMKECUydOpX169dTtmxZOnXqRFpaWoF/Z5HC1iK4AosGt+XmIB+SL2bST+cliYj8I4th4r+SoaGhtGzZkkmTJgHgcDgICgpi8ODBjBgx4rLxU6dOZcyYMezevRtXV9crvueIESNYs2YNq1atuuLzhmFQuXJlnn/+eV544QUAkpOTCQgIYMaMGfTo0eOKr0tPTyc9Pd35d0pKCkFBQSQnJ+Pl5XVd31vEDOlZ2bzx0w5mbzwCwL2NAvng4caUdXMxOZmISOFJSUnB29v7H3+/TduDlJGRQUxMDB07dvxvGKuVjh07Eh0dfcXXLFiwgLCwMCIiIggICKBhw4aMGjWK7OzsHGNatGhBt27d8Pf3p2nTpkyfPt35/MGDB4mPj8/xud7e3oSGhl71cwFGjx6Nt7e38xEUFHQjX1+k0Lm52HjvocaMerDRpfOS/rx0XpLWSxIRuZxpBen06dNkZ2cTEBCQY3tAQADx8fFXfM2BAweYN28e2dnZLF68mJEjRzJ27FjeeeedHGOmTJlCnTp1WLp0KQMHDuS5555j5syZAM73vp7PBXjllVdITk52Po4cOZKn7y1itkdDqzH76db4ebqxJyGVByatZvnuKx/WFhEprYrVvnWHw4G/vz/Tpk3DZrPRvHlzjh07xpgxY3jjjTecY1q0aMGoUaMAaNq0Kdu3b2fq1Kn07ds3z5/t5uaGm5tbvnwPEbM1r16Bnwe3ZeCszcQcPsvjMzcyrGMIg26rjdVqMTueiIjpTNuD5Ovri81mIyEh5x3IExISqFSp0hVfExgYSEhICDabzbmtXr16xMfHk5GR4RxTv379HK+rV68ecXFxAM73vp7PFSmJ/L3c+fap1vRuXQ3DuHQft6e/iiElLdPsaCIipjOtINntdpo3b05kZKRzm8PhIDIykrCwsCu+Jjw8nH379uFwOJzbYmNjCQwMxG63O8fs2bMnx+tiY2OpXv3SzTxr1KhBpUqVcnxuSkoK69evv+rnipRUdhcr73RpxAcPN8buYmXZrgS6TFrD3oRUs6OJiJjK1Mv8hw8fzvTp05k5cya7du1i4MCBnD9/nv79+wPQp08fXnnlFef4gQMHkpiYyJAhQ4iNjeXnn39m1KhRREREOMcMGzaMdevWMWrUKPbt28c333zDtGnTnGMsFgtDhw7lnXfeYcGCBfz555/06dOHypUr06VLl0L9/iJFxSMtgpj7TBiVvd05cPo8nSevYfGfJ8yOJSJiHsNkEydONKpVq2bY7XajVatWxrp165zPtW/f3ujbt2+O8WvXrjVCQ0MNNzc3o2bNmsa7775rZGVl5RizcOFCo2HDhoabm5tRt25dY9q0aTmedzgcxsiRI42AgADDzc3N6NChg7Fnz57ryp2cnGwARnJy8vV9YZEi7FRqmtHjk2ij+suLjOovLzJGLd5pZGZlmx1LRCTfXOvvt6nrIBVn17qOgkhxk5Xt4IOle5i28gAA4bUrMqFHUyqW00UKIlL8Ffl1kESkaHKxWfnXPfWY9GhTPOw21uw7w/0TV7PtSJLZ0URECo0Kkohc0X2NKzM/IpwavmU5npxGt6nRzN4QZ3YsEZFCoYIkIlcVEuDJT4PCuaN+ABnZDkb88Ccjvv+DtMzsf36xiEgxpoIkIn/Ly92VT3o358VON2GxwOyNR3jkk2iOnr1gdjQRkQKjgiQi/8hqtRBxW21m9m+Fj4crfxxN5v6Jq1m195TZ0URECoQKkohcs3Yhfiwc1JZGVbw5eyGTPp9vYPLyfTgcuhhWREoWFSQRuS5BFTyYOyCM7i2CMAwYs3QPT38VQ/JF3aJEREoOFSQRuW7urjbef7gx73Vt5LxFSedJq9l1IsXsaCIi+UIFSUTyrEeraswbEEYVnzIcOnOBBz9eww+bj5odS0TkhqkgicgNaVzVh0WD29IuxI+0TAfDv9vGqz/+SXqWlgIQkeJLBUlEblj5sna+6NeSIR3qYLHArPVxPDI1mmNJF82OJiKSJypIIpIvbFYLw+4I4fN+LfEu48q2o8ncN2EVUbFaCkBEih8VJBHJV7fd5M+iwf9dCqDfFxv4aNleLQUgIsVKngrSW2+9xYULl6+ie/HiRd56660bDiUixdtfSwH0bFUNw4APl8XSf8ZGzp7PMDuaiMg1sRiGcd3/WWez2Thx4gT+/v45tp85cwZ/f3+ys0v+yZkpKSl4e3uTnJyMl5eX2XFEiqy5m47w2vztpGc5qOJTho97NaNJkI/ZsUSklLrW3+887UEyDAOLxXLZ9m3btlGhQoW8vKWIlFDdWgTx47PhVK/owbGki3SbGs1X6w6Th/82ExEpNC7XM7h8+fJYLBYsFgshISE5SlJ2djbnzp1jwIAB+R5SRIq3+pW9WDi4LS/O3cbSHQmMnL+dmEOJjOraCA/7df0zJCJSKK7rENvMmTMxDIPHH3+c8ePH4+3t7XzObrcTHBxMWFhYgQQtanSITeT6GYbBp6sO8t6S3WQ7DOr4l2NK7+bU9i9ndjQRKSWu9fc7T+cgRUVFER4ejotL6f0vPxUkkbzbcDCRQd9s5mRqOh52G+891JgHmlQ2O5aIlAIFeg6Sp6cnu3btcv79008/0aVLF/71r3+RkaGrVETk77WqUYGfn7uFsJoVuZCRzXPfbuH1n7Zr9W0RKTLyVJCeeeYZYmNjAThw4ADdu3fHw8ODuXPn8tJLL+VrQBEpmfw83fj6yVAG3VYbgC+jD/PI1GiOJF6+hIiISGHLU0GKjY3l5ptvBmDu3Lm0b9+eb775hhkzZvD999/nZz4RKcFsVgsvdLqJL/q1xMfjP6tvT1xN5K4Es6OJSCmX58v8HQ4HAMuWLeOee+4BICgoiNOnT+dfOhEpFW6re2n17SZBPiRfzOSJmZt475fdZGU7zI4mIqVUngpSixYteOedd/jqq6+Iiori3nvvBeDgwYMEBATka0ARKR2qlvdg7jNh9GsTDMDUqP08+ul6ElLSzA0mIqVSngrS+PHj2bx5M4MGDeLVV1+ldu1L5xDMmzePNm3a5GtAESk97C5W3nygAZMfbUY5Nxc2HEzk3gmrWLNPe6ZFpHDl6TL/q0lLS8Nms+Hq6ppfb1lk6TJ/kYJ14NQ5np21md3xqVgsMKRDHQbfXgeb9fJV/EVErlWBroP0l5iYGOfl/vXr16dZs2Z5fatiRwVJpOClZWbz5oIdzN54BIC2tX35sPvN+Hm6mZxMRIqrAi1IJ0+epHv37kRFReHj4wNAUlISt912G7Nnz8bPzy/PwYsLFSSRwvPD5qO8+uN2LmZm4+/pxoSeTWlds6LZsUSkGCrQhSIHDx7MuXPn2LFjB4mJiSQmJrJ9+3ZSUlJ47rnn8hxaRORKujaryoJB4dTxL8fJ1HQenb6Oycv34XDohrciUjDytAfJ29ubZcuW0bJlyxzbN2zYwJ133klSUlJ+5SuytAdJpPBdyMjitfnb+WHzMQDahfjx4SNNqFhOh9xE5NoU6B4kh8NxxROxXV1dnesjiYjkNw+7C2O7NeGDhxrj5mJlZewp7p2wmo2HEs2OJiIlTJ4K0u23386QIUM4fvy4c9uxY8cYNmwYHTp0yLdwIiK5WSwWHmkZxE+DwqnpV5b4lDR6TFvHxyt0yE1E8k+eCtKkSZNISUkhODiYWrVqUatWLWrUqEFKSgoTJ07M74wiIpepW8mLhYPa0uXmymQ7DD5Ysof+MzZy5ly62dFEpATI82X+hmGwbNkydu/eDUC9evXo2LFjvoYrynQOkkjRYBgGczYe4Y0FO0jPclDJy52JjzalZXAFs6OJSBFUIJf5//777wwaNIh169Zd9qbJycm0adOGqVOncsstt+Q9eTGhgiRStOyOTyFi1mb2nzqPzWph+B0hDGxfC6sWlhSR/1EgJ2mPHz+ep5566opv6O3tzTPPPMO4ceOuP62IyA2qW8mLBYPa8mDTKmQ7DMYs3UPfLzZwWofcRCQPrqsgbdu2jbvuuuuqz995553ExMTccCgRkbwo6+bCuEcuXeXm7mpl1d7T3PPRKqL3nzE7mogUM9dVkBISEv72PmsuLi6cOnXqhkOJiOTVX1e5LRjU1rmwZK9P1/HRsr1k6yo3EblG11WQqlSpwvbt26/6/B9//EFgYOANhxIRuVEhAZ78NCicbs2r4jDgw2WxPPbZek6mpJkdTUSKgesqSPfccw8jR44kLe3yf2AuXrzIG2+8wX333Zdv4UREboSH3YUx3Zow7pEmeNhtrN1/hrs/WkVUrPZ0i8jfu66r2BISEmjWrBk2m41BgwZx0003AbB7924mT55MdnY2mzdvJiAgoMACFxW6ik2keNl38hyDvtnM7vhUAAbeWovhd4TgasvTcnAiUkwVyGX+AIcPH2bgwIEsXbqUv15qsVjo1KkTkydPpkaNGjeWvJhQQRIpftIys3nn5518vS4OgGbVfJjQsylVy3uYnExECkuBFaS/nD17ln379mEYBnXq1KF8+fJ5DlscqSCJFF+L/zzBy/P+IDU9Cy/3S4fhOjWoZHYsESkEBV6QSjsVJJHi7UjiBQZ9u4VtR5IA6BtWnVfuqYe7q83cYCJSoApkoUgRkZIiqIIHc58J4+l2NQGYGX2Yrh+v5cCpcyYnE5GiQAVJREotu4uVf91Tjy/6t6RCWTs7T6Rw38TVfB9z1OxoImIyFSQRKfVuu8mfX4bcQuuaFbiQkc3zc7cxbM5WzqVnmR1NREyigiQiAgR4uTPrydY8f0cIVgv8uOUY901YxfZjyWZHExETqCCJiPyHzWphcIc6zHkmjMre7hw6c4EHP17Dp6sOoOtZREoXFSQRkVxaBldg8ZBbuLN+AJnZBu/8vIvHZ2zkzLl0s6OJSCFRQRIRuQIfDzufPNactzs3wO5iZfmeU9z90SrW7jttdjQRKQQqSCIiV2GxWHgsLJgFg8Kp7V+Ok6np9PpsPWOW7iYz22F2PBEpQCpIIiL/oG4lLxYOakvPVkEYBkxevp9HPonmSOIFs6OJSAFRQRIRuQZl7DZGd23M5Eeb4enuwpa4JO75aBULtx03O5qIFAAVJBGR63Bv40B+GXILzauXJzU9i8HfbuHFuds4rzWTREoUFSQRketUtbwHc55uzXO318ZigbkxR7l/4mqtmSRSgqggiYjkgYvNyvA7b+Lbp1oT6O3OgdPnnWsmORxaM0mkuFNBEhG5Aa1rVuSXIbfQqcF/10zqN2MjJ1PTzI4mIjdABUlE5Ab5eNiZ2rs57z7YEHdXKytjT3HPR6tYvvuk2dFEJI9UkERE8oHFYqFXaHUWDmpL3UqenD6XQf8ZG3lzwQ7SMrPNjici10kFSUQkH9UJ8GR+RDj9w4MBmLH2EF0mryE2IdXcYCJyXVSQRETymburjTfub8AX/VviW87O7vhU7p+4mq+iD+mmtyLFhAqSiEgBue0mf34Z0o72IX6kZzkY+dMOnvpyk256K1IMqCCJiBQgP083vujXktfvq4/dZmXZrpPc9dEqVsaeMjuaiPwNFSQRkQJmtVp4vG0NfhoUTh3/cpxKTafP5xt4a+FOncAtUkQViYI0efJkgoODcXd3JzQ0lA0bNvzt+KSkJCIiIggMDMTNzY2QkBAWL17sfP7NN9/EYrHkeNStWzfHe9x6662XjRkwYECBfD8REYB6gV4sHNyWPmHVAfh8zUGdwC1SRLmYHWDOnDkMHz6cqVOnEhoayvjx4+nUqRN79uzB39//svEZGRnccccd+Pv7M2/ePKpUqcLhw4fx8fHJMa5BgwYsW7bM+beLy+Vf9amnnuKtt95y/u3h4ZF/X0xE5ArcXW281bkh7UP8eGneH84TuF+9tx6Pta6OxWIxO6KIUAQK0rhx43jqqafo378/AFOnTuXnn3/m888/Z8SIEZeN//zzz0lMTGTt2rW4uroCEBwcfNk4FxcXKlWq9Lef7eHh8Y9jREQKQod6Afwy9BZenPsHUbGneP2nHSzffZIPHm6Cn6eb2fFESj1TD7FlZGQQExNDx44dndusVisdO3YkOjr6iq9ZsGABYWFhREREEBAQQMOGDRk1ahTZ2TmP4+/du5fKlStTs2ZNevXqRVxc3GXvNWvWLHx9fWnYsCGvvPIKFy5cuGrW9PR0UlJScjxERG6Ev6c7M/q35M3762N3sbJ8zynuGr+SyF0JZkcTKfVMLUinT58mOzubgICAHNsDAgKIj4+/4msOHDjAvHnzyM7OZvHixYwcOZKxY8fyzjvvOMeEhoYyY8YMlixZwpQpUzh48CC33HILqan/Pc7/6KOP8vXXX7N8+XJeeeUVvvrqK3r37n3VrKNHj8bb29v5CAoKusFvLyJyaQXufuE1nCtwnzmfwRMzN/Ha/D+5mKETuEXMYjFMXLXs+PHjVKlShbVr1xIWFubc/tJLLxEVFcX69esve01ISAhpaWkcPHgQm80GXDpMN2bMGE6cOHHFz0lKSqJ69eqMGzeOJ5544opjfv/9dzp06MC+ffuoVavWZc+np6eTnv7ftUtSUlIICgoiOTkZLy+v6/reIiJXkpaZzZile/hs9UEAavmV5aMeTWlYxdvkZCIlR0pKCt7e3v/4+23qHiRfX19sNhsJCTl3JyckJFz13KDAwEBCQkKc5QigXr16xMfHk5GRccXX+Pj4EBISwr59+66aJTQ0FOCqY9zc3PDy8srxEBHJT+6uNkbeV5+vnmiFv6cb+0+d58GP1zBlxX6yHVqBW6QwmVqQ7HY7zZs3JzIy0rnN4XAQGRmZY4/S/woPD2ffvn04HA7nttjYWAIDA7Hb7Vd8zblz59i/fz+BgYFXzbJ161aAvx0jIlIYbqnjx9Kh7birQSUysw3eX7KbntPXcfTs1c+TFJH8Zfo6SMOHD2f69OnMnDmTXbt2MXDgQM6fP++8qq1Pnz688sorzvEDBw4kMTGRIUOGEBsby88//8yoUaOIiIhwjnnhhReIiori0KFDrF27lgcffBCbzUbPnj0B2L9/P2+//TYxMTEcOnSIBQsW0KdPH9q1a0fjxo0LdwJERK6gfFk7U3o344OHG1PWbmPDwUTu/mgVP209ZnY0kVLB9Mv8u3fvzqlTp3j99deJj4/n5ptvZsmSJc4Tt+Pi4rBa/9vjgoKCWLp0KcOGDaNx48ZUqVKFIUOG8PLLLzvHHD16lJ49e3LmzBn8/Pxo27Yt69atw8/PD7i052rZsmWMHz+e8+fPExQUxEMPPcRrr71WuF9eRORvWCwWHmkRRGiNCgybs5XNcUkMmb2VZbtO8k7nhnh7uJodUaTEMvUk7eLsWk/yEhHJD1nZDj5esZ+PIveS7TAI9HZnbLcmtKnta3Y0kWKlWJykLSIi18bFZuW5DnWYNyCMGr5lOZGcxqOfruedRbqfm0hBUEESESlGmlYrz8/PteXR0GoAfLr60v3cdp3Q4rUi+UkFSUSkmPGwuzDqwUZ82qcFFcva2R2fSudJa/gkSssBiOQXFSQRkWKqY/0Alg5rR8d6AWRkOxj9y24e1XIAIvlCBUlEpBjzLefG9D7Nea9rIzzsNtYfTOTu8av4PuYougZHJO9UkEREijmLxUKPVtX4ZcgtNKvmQ2p6Fs/P3cazszaTeP7KdxgQkb+ngiQiUkJUr1iW754J44U7Q3CxWvhlezydxq9k+e6TZkcTKXZUkEREShAXm5VBt9dhfkQ4tf3LcSo1nf4zNvKvH//kfHqW2fFEig0VJBGREqhhFW8WDW7L4+E1APhmfRz3TFhFzOGzJicTKR5UkERESih3Vxuv31+fWU+GEujtzuEzF+g2dS1jlu4mI8vxz28gUoqpIImIlHDhtX1ZMrQdXZtWwWHA5OX76TJ5DXviU82OJlJkqSCJiJQC3mVcGdf9Zqb0akZ5D1d2nkjh/kmrmbZSi0uKXIkKkohIKXJ3o0CWDmvH7XX9ychyMGrxbnpOW0fcGS0uKfK/VJBEREoZf093PuvbgvcfakRZu40NhxK566OVfLshTotLivyHCpKISClksVjo3rIaS4a2o1VwBS5kZPPKD3/y+IyNJKSkmR1PxHQqSCIipVhQBQ++fbo1/7qnLnableV7TnHnhytZsO242dFETKWCJCJSytmsFp5uV4tFz7WlYRUvki9m8ty3W4j4ZjNndasSKaVUkEREBICQAE9+fDacIR3qYLNa+PmPE9w5fiXLdiaYHU2k0KkgiYiIk6vNyrA7Qvjx2TbOW5U8+eUmXpy7jZS0TLPjiRQaFSQREblM46o+LBrclqfb1cRigbkxR7nrw5Ws3nva7GgihUIFSURErsjd1ca/7qnHnKfDqFbBg+PJafT+bD0j52/nQoZufCslmwqSiIj8rVY1KvDLkFvo3boaAF+tO8zdH61i46FEk5OJFBwVJBER+Udl3Vx4p0sjvnqilfPGt498Es27P+8kLTPb7Hgi+U4FSURErtktdfxYOqwd3ZpXxTBg+qqD3DthFVvizpodTSRfqSCJiMh18XJ3ZUy3JnzWtwX+nm7sP3Weh6as5YMlu0nP0t4kKRlUkEREJE861Avg12Ht6HJzZRwGfLxiP/dPXM2fR5PNjiZyw1SQREQkz3w87Izv0ZSpvZtTsayd2IRzdPl4DeN+3UNGlsPseCJ5poIkIiI37K6Glfh1WDvubRxItsNgwu/7eGDSanYc194kKZ5UkEREJF9ULOfG5EebMfnRZlQoa2d3fCqdJ61h/LJYMrO1N0mKFxUkERHJV/c2DuTXYe24u2ElshwG45ftpfOkNew8nmJ2NJFrpoIkIiL5zrecGx/3asbEnk0p7+HKzhMpPDBptfYmSbGhgiQiIgXCYrFwf5PK/DqsPXc10N4kKV5UkEREpED5eboxpXczJvRsik+uvUm60k2KKhUkEREpcBaLhQeaVOa3Ye3p1CDgv3uTJq/RlW5SJKkgiYhIofHzdGNq7+Z81ONmynu4sutECp0nrWHcb9qbJEWLCpKIiBQqi8VC55ur8Ouw9tzT6NK5SRMi9/LAJK3CLUWHCpKIiJjCz9ONj3s1Z/Kjzaj4n3WTuny8Rvd0kyJBBUlEREz117pJ9zepTLbD4OMV+7lvwmq2HkkyO5qUYipIIiJiuorl3JjY89I93XzLubH35Dm6fryG0Yt3kZapvUlS+FSQRESkyLirYSV+G9aOB5tWwWHAJysPcPdHq9h4KNHsaFLKqCCJiEiRUr6snQ+738xnfVsQ4OXGwdPneeSTaN5csIPz6Vlmx5NSQgVJRESKpA71Avh1WHu6twjCMGDG2kN0Gr+S1XtPmx1NSgEVJBERKbK8y7jy/sON+eqJVlTxKcPRsxfp/dl6Rnz/BylpmWbHkxJMBUlERIq8W+r4sXRYO/qEVQdg9sYj3DEuimU7E0xOJiWVCpKIiBQL5dxceKtzQ+Y83Zrgih4kpKTz5JebeO7bLSSezzA7npQwKkgiIlKshNasyJKh7XimXU2sFliw7Tgdx0WxYNtxDMMwO56UECpIIiJS7Li72njlnnr8+Gw4dSt5kng+g+e+3cJTX8YQn5xmdjwpAVSQRESk2GoS5MOCQW0Z1jEEV5uFZbsSuOPDKGZviNPeJLkhKkgiIlKs2V2sDOlYh0WDb6FJkA+paVmM+OFPHp2+nsNnzpsdT4opFSQRESkRbqrkyQ8D2/DavfVwd7USfeAMncavZPrKA2RlO8yOJ8WMCpKIiJQYNquFJ2+pya9D29OmVkXSMh28u3gXXaesZdeJFLPjSTGigiQiIiVOtYoezHoylPcfaoSnuwt/HE3m/omr+b+le3TzW7kmKkgiIlIiWSwWuresRuTw9tzVoBJZDoNJy/dx7wTd/Fb+mQqSiIiUaP5e7kx9rDlTejXDz9ON/afO021qNCPnbydVtyuRq1BBEhGRUuHuRoEs+8/NbwG+WneYO8at1O1K5IpUkEREpNTw9rh089tvngylekUP4lPSePLLTUR8s5lTqelmx5MiRAVJRERKnTa1fVkypB3PtK+JzWrh5z9O0HFcFN9tOqIFJgVQQRIRkVKqjN3GK3fX46eIcBpU9iL5YiYvzfuDXp+u59BpLTBZ2qkgiYhIqdawijc/RYTzyt11cXe1snb/pQUmp6zYT6YWmCy1VJBERKTUc7FZeaZ9LZYObUfb2r6kZzl4f8luHpi0hj+OJpkdT0yggiQiIvIf1SuW5asnWvF/3Zrg4+HKrhMpdJm8hrcX7eR8epbZ8aQQqSCJiIj8D4vFwsPNq7JseHu63FwZhwGfrT7InR+uZPmek2bHk0KigiQiInIFvuXcGN+jKTP6t6Rq+TIcS7pI/y82MvjbLVoSoBRQQRIREfkbt97kz6/D2vFk2xpYLbBw23E6jF3BnI1xWhKgBFNBEhER+Qcedhdeu68+P0W0pWEVL1LSsnj5+z/pPm0d+06eMzueFAAVJBERkWvUqKo3858N57V761HG1caGg4nc89Eqxi+LJT0r2+x4ko+KREGaPHkywcHBuLu7ExoayoYNG/52fFJSEhEREQQGBuLm5kZISAiLFy92Pv/mm29isVhyPOrWrZvjPdLS0oiIiKBixYqUK1eOhx56iIQE3Y9HRET+novNypO31OTXYe249SY/MrIdjF+2l3s+WsX6A2fMjif5xPSCNGfOHIYPH84bb7zB5s2badKkCZ06deLkyStfKZCRkcEdd9zBoUOHmDdvHnv27GH69OlUqVIlx7gGDRpw4sQJ52P16tU5nh82bBgLFy5k7ty5REVFcfz4cbp27Vpg31NEREqWoAoefNGvJRN7NsW3nBv7T52n+7R1vDzvD5IuZJgdT26QxTD5DLPQ0FBatmzJpEmTAHA4HAQFBTF48GBGjBhx2fipU6cyZswYdu/ejaur6xXf880332T+/Pls3br1is8nJyfj5+fHN998w8MPPwzA7t27qVevHtHR0bRu3fofc6ekpODt7U1ycjJeXl7X+G1FRKQkSr6QyXtLdvPthjgAfMvZGXlffR5oUhmLxWJyOvlf1/r7beoepIyMDGJiYujYsaNzm9VqpWPHjkRHR1/xNQsWLCAsLIyIiAgCAgJo2LAho0aNIjs757HfvXv3UrlyZWrWrEmvXr2Ii4tzPhcTE0NmZmaOz61bty7VqlW76uemp6eTkpKS4yEiIgLg7eHK6K6NmDsgjDr+5Th9LoMhs7fS5/MNHD6j+7oVR6YWpNOnT5OdnU1AQECO7QEBAcTHx1/xNQcOHGDevHlkZ2ezePFiRo4cydixY3nnnXecY0JDQ5kxYwZLlixhypQpHDx4kFtuuYXU1FQA4uPjsdvt+Pj4XPPnjh49Gm9vb+cjKCjoBr65iIiURC2DK/Dzc7fwwp0h2F2srNp7mjs/XMnk5fvIyNJ93YoT089Bul4OhwN/f3+mTZtG8+bN6d69O6+++ipTp051jrn77rvp1q0bjRs3plOnTixevJikpCS+++67PH/uK6+8QnJysvNx5MiR/Pg6IiJSwthdrAy6vQ6/Dm1HeO2KpGc5GLN0D/dOWMXGQ4lmx5NrZGpB8vX1xWazXXb1WEJCApUqVbriawIDAwkJCcFmszm31atXj/j4eDIyrnxSnI+PDyEhIezbtw+ASpUqkZGRQVJS0jV/rpubG15eXjkeIiIiVxPsW5avnwjlw+5NqFjWzt6T5+g2NZoR3+sk7uLA1IJkt9tp3rw5kZGRzm0Oh4PIyEjCwsKu+Jrw8HD27duHw/HfXZWxsbEEBgZit9uv+Jpz586xf/9+AgMDAWjevDmurq45PnfPnj3ExcVd9XNFRESul8Vi4cGmVYl8vj09Wl46NWP2xiN0GBvFj1uOaiXuIsz0Q2zDhw9n+vTpzJw5k127djFw4EDOnz9P//79AejTpw+vvPKKc/zAgQNJTExkyJAhxMbG8vPPPzNq1CgiIiKcY1544QWioqI4dOgQa9eu5cEHH8Rms9GzZ08AvL29eeKJJxg+fDjLly8nJiaG/v37ExYWdk1XsImIiFwPHw877z3U2HkS95nzGQybs41en67nwCmtxF0UuZgdoHv37pw6dYrXX3+d+Ph4br75ZpYsWeI8cTsuLg6r9b89LigoiKVLlzJs2DAaN25MlSpVGDJkCC+//LJzzNGjR+nZsydnzpzBz8+Ptm3bsm7dOvz8/JxjPvzwQ6xWKw899BDp6el06tSJjz/+uPC+uIiIlDp/ncQ9fdUBJkTuZe3+M9w1fhUDb63FwFtr4e5q++c3kUJh+jpIxZXWQRIRkRsRd+YCI3/aTlTsKQBq+Jbl7c4NaVvH1+RkJVuxWAdJRESktKpW0YMZ/Vsy+dFm+Hu6cfD0eXp/tp4hs7dwMjXN7HilngqSiIiISSwWC/c2DmTZ8+3p1yYYqwV+2nqcDmOj+GrdYbIdOshjFh1iyyMdYhMRkfz2x9EkXv1xO38eSwagSZAP73ZpSMMq3iYnKzl0iE1ERKSYaVzVh/kR4fz7gQaUc3Nh25EkHpi0mn8v3EFqWqbZ8UoVFSQREZEixGa10LdNMJHPt+e+xoE4DPhizSE6joti0R/HtXZSIVFBEhERKYICvNyZ9Ggzvny8FdUrepCQks6gb7bQ94uNHDqtG+AWNBUkERGRIqxdiB9Lh7ZjSIc62G1WVsae4s7xK/nwt1jSMrPNjldiqSCJiIgUce6uNobdEcLSYe24pY4vGVkOPorcS6fxK53rKEn+UkESEREpJmr4luXLx1sx+dFmBHi5cfjMBfp+voFnZ8VwIvmi2fFKFBUkERGRYsS5dtLw9jweXgOb1cLiP+PpODaKT1cdIDPb8c9vIv9I6yDlkdZBEhGRomDn8RRem/8nm+OSALgpwJO3uzSkVY0K5gYrorQOkoiISClQv7IX8wa04YOHGlPew5U9Cak88kk0w7/byqnUdLPjFVsqSCIiIsWc1WrhkZZB/P78rfRsFQTAD5uPcfvYFXwZfUi3LMkDHWLLIx1iExGRompL3Flem7+dHcdTAGhYxYu3OzekabXyJicz37X+fqsg5ZEKkoiIFGXZDoNZ6w8zZukeUtOysFigR8sgXupUl/Jl7WbHM43OQRIRESnFbFYLfcKC+f35W3moWVUMA77dcITbxq7g2w1xOHTY7W9pD1IeaQ+SiIgUJxsOJvL6T9vZHZ8KQJMgH97p3JBGVb1NTla4dIitgKkgiYhIcZOV7WBm9GE+/C2Wc+mXDrs92qoaL3a6CR+P0nHYTYfYREREJAcXm5Un2tbg9+fb82DTKhgGzFofx23/t4LZOuyWg/Yg5ZH2IImISHG3/sAZXv9pB3sS/nvY7e3ODWhc1cfcYAVIh9gKmAqSiIiUBJnZDr7MdditR8tqvNTpphJ5tZsOsYmIiMg/cr3CYbdvN8Rx29gVfL3ucKldZFJ7kPJIe5BERKQkyn21W8MqXvz7gYY0r14yFpnUIbYCpoIkIiIlVVa2g6/XHWbsb7GkpmUB0K15VV6+uy6+5dxMTndjdIhNRERE8sTFZqVfeA1+f/5WHm5eFYC5MUe57f9W8MWag2RlO0xOWPC0BymPtAdJRERKi5jDZ3ljwXa2H7t0b7e6lTx584EGtK5Z0eRk10+H2AqYCpKIiJQm2Q6D2RvjGLN0D0kXMgG4v0llXr2nHpW83U1Od+10iE1ERETyjc1qoVdodZY/fyu9W1fDYoGF245z+9gVfLxiH+lZ2WZHzFfag5RH2oMkIiKl2fZjybyxYAcxh88CEFzRg9fvr8/tdQNMTvb3dIitgKkgiYhIaWcYBj9uOcboX3ZzKjUdgNvr+jPyvvrU8C1rcrorU0EqYCpIIiIil6SmZTLx9318vvogWQ4Du83KE7fUYNBttSnr5mJ2vBxUkAqYCpKIiEhO+06e461FO1kZewqAAC83/nVPPR5oUhmLxWJyuktUkAqYCpKIiMjlDMNg2a6TvL1oJ3GJFwBoUb08bz7QgIZVvE1Op4JU4FSQREREri4tM5vPVh9k0u/7uJiZ7bwJ7gt3hlDRxNW4VZAKmAqSiIjIPzuRfJHRi3ezYNtxALzcXRh2RwiPta6Oi63wVxtSQSpgKkgiIiLXbsPBRN5csIOdJy6txh0SUI437m9AeG3fQs2hglTAVJBERESuz1+rcf/f0j2c/c9q3J0aBPDavfUJquBRKBlUkAqYCpKIiEjeJF/I5MNlsXy17jDZDgO7i5WnbqnBs7cW/LIAKkgFTAVJRETkxsQmpPLWwp2s3ncauLQswIi769Ll5ioFtiyAClIBU0ESERG5cYZh8OvOBN79eZdzWYBm1Xx44/4GNAnyyffP081qRUREpMizWCx0alCJX4e148VON+Fht7E5LonOk9cwefk+03KpIImIiIjp3F1tRNxWm+Uv3ErXZlWwWCC0RgXT8ugQWx7pEJuIiEjBOXT6PMEFcMNbHWITERGRYqsgytH1UEESERERyUUFSURERCQXFSQRERGRXFSQRERERHJRQRIRERHJRQVJREREJBcVJBEREZFcVJBEREREclFBEhEREclFBUlEREQkFxUkERERkVxUkERERERyUUESERERycXF7ADFlWEYAKSkpJicRERERK7VX7/bf/2OX40KUh6lpqYCEBQUZHISERERuV6pqal4e3tf9XmL8U8VSq7I4XBw/PhxPD09sVgs+fa+KSkpBAUFceTIEby8vPLtfeXKNN+FR3NdeDTXhUdzXXjya64NwyA1NZXKlStjtV79TCPtQcojq9VK1apVC+z9vby89H+2QqT5Ljya68KjuS48muvCkx9z/Xd7jv6ik7RFREREclFBEhEREclFBamIcXNz44033sDNzc3sKKWC5rvwaK4Lj+a68GiuC09hz7VO0hYRERHJRXuQRERERHJRQRIRERHJRQVJREREJBcVJBEREZFcVJCKmMmTJxMcHIy7uzuhoaFs2LDB7EjF3ujRo2nZsiWenp74+/vTpUsX9uzZk2NMWloaERERVKxYkXLlyvHQQw+RkJBgUuKS47333sNisTB06FDnNs11/jl27Bi9e/emYsWKlClThkaNGrFp0ybn84Zh8PrrrxMYGEiZMmXo2LEje/fuNTFx8ZSdnc3IkSOpUaMGZcqUoVatWrz99ts57uWluc6blStXcv/991O5cmUsFgvz58/P8fy1zGtiYiK9evXCy8sLHx8fnnjiCc6dO3fD2VSQipA5c+YwfPhw3njjDTZv3kyTJk3o1KkTJ0+eNDtasRYVFUVERATr1q3jt99+IzMzkzvvvJPz5887xwwbNoyFCxcyd+5coqKiOH78OF27djUxdfG3ceNGPvnkExo3bpxju+Y6f5w9e5bw8HBcXV355Zdf2LlzJ2PHjqV8+fLOMR988AETJkxg6tSprF+/nrJly9KpUyfS0tJMTF78vP/++0yZMoVJkyaxa9cu3n//fT744AMmTpzoHKO5zpvz58/TpEkTJk+efMXnr2Vee/XqxY4dO/jtt99YtGgRK1eu5Omnn77xcIYUGa1atTIiIiKcf2dnZxuVK1c2Ro8ebWKqkufkyZMGYERFRRmGYRhJSUmGq6urMXfuXOeYXbt2GYARHR1tVsxiLTU11ahTp47x22+/Ge3btzeGDBliGIbmOj+9/PLLRtu2ba/6vMPhMCpVqmSMGTPGuS0pKclwc3Mzvv3228KIWGLce++9xuOPP55jW9euXY1evXoZhqG5zi+A8eOPPzr/vpZ53blzpwEYGzdudI755ZdfDIvFYhw7duyG8mgPUhGRkZFBTEwMHTt2dG6zWq107NiR6OhoE5OVPMnJyQBUqFABgJiYGDIzM3PMfd26dalWrZrmPo8iIiK49957c8wpaK7z04IFC2jRogXdunXD39+fpk2bMn36dOfzBw8eJD4+Psdce3t7Exoaqrm+Tm3atCEyMpLY2FgAtm3bxurVq7n77rsBzXVBuZZ5jY6OxsfHhxYtWjjHdOzYEavVyvr162/o83Wz2iLi9OnTZGdnExAQkGN7QEAAu3fvNilVyeNwOBg6dCjh4eE0bNgQgPj4eOx2Oz4+PjnGBgQEEB8fb0LK4m327Nls3ryZjRs3Xvac5jr/HDhwgClTpjB8+HD+9a9/sXHjRp577jnsdjt9+/Z1zueV/k3RXF+fESNGkJKSQt26dbHZbGRnZ/Puu+/Sq1cvAM11AbmWeY2Pj8ff3z/H8y4uLlSoUOGG514FSUqViIgItm/fzurVq82OUiIdOXKEIUOG8Ntvv+Hu7m52nBLN4XDQokULRo0aBUDTpk3Zvn07U6dOpW/fvianK1m+++47Zs2axTfffEODBg3YunUrQ4cOpXLlyprrEkyH2IoIX19fbDbbZVfzJCQkUKlSJZNSlSyDBg1i0aJFLF++nKpVqzq3V6pUiYyMDJKSknKM19xfv5iYGE6ePEmzZs1wcXHBxcWFqKgoJkyYgIuLCwEBAZrrfBIYGEj9+vVzbKtXrx5xcXEAzvnUvyk37sUXX2TEiBH06NGDRo0a8dhjjzFs2DBGjx4NaK4LyrXMa6VKlS67kCkrK4vExMQbnnsVpCLCbrfTvHlzIiMjndscDgeRkZGEhYWZmKz4MwyDQYMG8eOPP/L7779To0aNHM83b94cV1fXHHO/Z88e4uLiNPfXqUOHDvz5559s3brV+WjRogW9evVy/m/Ndf4IDw+/bLmK2NhYqlevDkCNGjWoVKlSjrlOSUlh/fr1muvrdOHCBazWnD+XNpsNh8MBaK4LyrXMa1hYGElJScTExDjH/P777zgcDkJDQ28swA2d4i35avbs2Yabm5sxY8YMY+fOncbTTz9t+Pj4GPHx8WZHK9YGDhxoeHt7GytWrDBOnDjhfFy4cME5ZsCAAUa1atWM33//3di0aZMRFhZmhIWFmZi65Pjfq9gMQ3OdXzZs2GC4uLgY7777rrF3715j1qxZhoeHh/H11187x7z33nuGj4+P8dNPPxl//PGH0blzZ6NGjRrGxYsXTUxe/PTt29eoUqWKsWjRIuPgwYPGDz/8YPj6+hovvfSSc4zmOm9SU1ONLVu2GFu2bDEAY9y4ccaWLVuMw4cPG4ZxbfN61113GU2bNjXWr19vrF692qhTp47Rs2fPG86mglTETJw40ahWrZpht9uNVq1aGevWrTM7UrEHXPHxxRdfOMdcvHjRePbZZ43y5csbHh4exoMPPmicOHHCvNAlSO6CpLnOPwsXLjQaNmxouLm5GXXr1jWmTZuW43mHw2GMHDnSCAgIMNzc3IwOHToYe/bsMSlt8ZWSkmIMGTLEqFatmuHu7m7UrFnTePXVV4309HTnGM113ixfvvyK/z737dvXMIxrm9czZ84YPXv2NMqVK2d4eXkZ/fv3N1JTU284m8Uw/mcpUBERERHROUgiIiIiuakgiYiIiOSigiQiIiKSiwqSiIiISC4qSCIiIiK5qCCJiIiI5KKCJCIiIpKLCpKIiIhILipIIiLXKDg4mPHjx5sdQ0QKgQqSiBRJ/fr1o0uXLgDceuutDB06tNA+e8aMGfj4+Fy2fePGjTz99NOFlkNEzONidgARkcKSkZGB3W7P8+v9/PzyMY2IFGXagyQiRVq/fv2Iiorio48+wmKxYLFYOHToEADbt2/n7rvvply5cgQEBPDYY49x+vRp52tvvfVWBg0axNChQ/H19aVTp04AjBs3jkaNGlG2bFmCgoJ49tlnOXfuHAArVqygf//+JCcnOz/vzTffBC4/xBYXF0fnzp0pV64cXl5ePPLIIyQkJDiff/PNN7n55pv56quvCA4Oxtvbmx49epCamuocM2/ePBo1akSZMmWoWLEiHTt25Pz58wU0myJyrVSQRKRI++ijjwgLC+Opp57ixIkTnDhxgqCgIJKSkrj99ttp2rQpmzZtYsmSJSQkJPDII4/keP3MmTOx2+2sWbOGqVOnAmC1WpkwYQI7duxg5syZ/P7777z00ksAtGnThvHjx+Pl5eX8vBdeeOGyXA6Hg86dO5OYmEhUVBS//fYbBw4coHv37jnG7d+/n/nz57No0SIWLVpEVFQU7733HgAnTpygZ8+ePP744+zatYsVK1bQtWtXdA9xEfPpEJuIFGne3t7Y7XY8PDyoVKmSc/ukSZNo2rQpo0aNcm77/PPPCQoKIjY2lpCQEADq1KnDBx98kOM9//d8puDgYN555x0GDBjAxx9/jN1ux9vbG4vFkuPzcouMjOTPP//k4MGDBAUFAfDll1/SoEEDNm7cSMuWLYFLRWrGjBl4enoC8NhjjxEZGcm7777LiRMnyMrKomvXrlSvXh2ARo0a3cBsiUh+0R4kESmWtm3bxvLlyylXrpzzUbduXeDSXpu/NG/e/LLXLlu2jA4dOlClShU8PT157LHHOHPmDBcuXLjmz9+1axdBQUHOcgRQv359fHx82LVrl3NbcHCwsxwBBAYGcvLkSQCaNGlChw4daNSoEd26dWP69OmcPXv22idBRAqMCpKIFEvnzp3j/vvvZ+vWrTkee/fupV27ds5xZcuWzfG6Q4cOcd9999G4cWO+//57YmJimDx5MnDpJO785urqmuNvi8WCw+EAwGaz8dtvv/HLL79Qv359Jk6cyE033cTBgwfzPYeIXB8VJBEp8ux2O9nZ2Tm2NWvWjB07dhAcHEzt2rVzPHKXov8VExODw+Fg7NixtG7dmpCQEI4fP/6Pn5dbvXr1OHLkCEeOHHFu27lzJ0lJSdSvX/+av5vFYiE8PJx///vfbNmyBbvdzo8//njNrxeRgqGCJCJFXnBwMOvXr+fQoUOcPn0ah8NBREQEiYmJ9OzZk40bN7J//36WLl1K//79/7bc1K5dm8zMTCZOnMiBAwf46quvnCdv/+/nnTt3jsjISE6fPn3FQ28dO3akUaNG9OrVi82bN7Nhwwb69OlD+/btadGixTV9r/Xr1zNq1Cg2bdpEXFwcP/zwA6dOnaJevXrXN0Eiku9UkESkyHvhhRew2WzUr18fPz8/4uLiqFy5MmvWrCE7O5s777yTRo0aMXToUHx8fLBar/5PW5MmTRg3bhzvv/8+DRs2ZNasWYwePTrHmDZt2jBgwAC6d++On5/fZSd5w6U9Pz/99BPly5enXbt2dOzYkZo1azJnzpxr/l5eXl6sXLmSe+65h5CQEF577TXGjh3L3Xfffe2TIyIFwmLoelIRERGRHLQHSURERCQXFSQRERGRXFSQRERERHJRQRIRERHJRQVJREREJBcVJBEREZFcVJBEREREclFBEhEREclFBUlEREQkFxUkERERkVxUkERERERy+X8EUD4tUyC13AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp.predict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f15249",
   "metadata": {},
   "source": [
    "## Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e624dd0a",
   "metadata": {},
   "source": [
    "With the initial parameters, the cost function doesn't look that good. It is decreasing which is a good sign but it isn't flattening out. I have tried, multiple different values but this some seems like the best fit.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "8c18aa92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.762712</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.525424</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "149      0.444444     0.416667      0.694915     0.708333\n",
       "34       0.166667     0.458333      0.084746     0.041667\n",
       "89       0.333333     0.208333      0.508475     0.500000\n",
       "116      0.611111     0.416667      0.762712     0.708333\n",
       "67       0.416667     0.291667      0.525424     0.375000"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_norm = data[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "df_norm.sample(n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "37d9a34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     species\n",
       "139        2\n",
       "89         1\n",
       "115        2\n",
       "122        2\n",
       "5          0"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = data[['species']].replace(['setosa','versicolor','virginica'],[0,1,2])\n",
    "target.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "8ee41cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.118644</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.644068</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.593220</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal_length  sepal_width  petal_length  petal_width  species\n",
       "18      0.388889     0.750000      0.118644     0.083333        0\n",
       "70      0.444444     0.500000      0.644068     0.708333        1\n",
       "84      0.305556     0.416667      0.593220     0.583333        1\n",
       "62      0.472222     0.083333      0.508475     0.375000        1\n",
       "27      0.250000     0.625000      0.084746     0.041667        0"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_norm, target], axis=1)\n",
    "df.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "d071dde6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  species\n",
       "0      0.222222     0.625000      0.067797     0.041667        0\n",
       "1      0.166667     0.416667      0.067797     0.041667        0\n",
       "2      0.111111     0.500000      0.050847     0.041667        0\n",
       "3      0.083333     0.458333      0.084746     0.041667        0\n",
       "4      0.194444     0.666667      0.067797     0.041667        0"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "7c1072a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "columns = df.columns.drop('species')\n",
    "X = df[columns]\n",
    "\n",
    "y = df.species\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "7087805e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.04745243e-01, -3.47943889e-01,  4.46396064e-01,\n",
       "        -1.41449056e-01],\n",
       "       [-2.70589680e-01,  1.19419379e-01, -2.72792188e-01,\n",
       "        -1.92004094e-01],\n",
       "       [ 3.44449572e-01,  5.10917533e-02,  4.44596169e-01,\n",
       "        -1.59260067e-01],\n",
       "       [ 4.69520828e-02, -8.29432637e-02,  3.62004460e-01,\n",
       "         4.37726642e-01],\n",
       "       [-4.53777628e-01, -6.26687506e-02,  4.43059805e-01,\n",
       "        -3.11381510e-01],\n",
       "       [-2.22310816e-01,  4.09971049e-01,  1.87330619e-01,\n",
       "         1.35344327e-01],\n",
       "       [-2.40849240e-01, -4.36966443e-01, -1.14267150e-01,\n",
       "         2.26472297e-01],\n",
       "       [ 1.28234098e-01, -2.86095540e-01,  2.54299526e-01,\n",
       "         4.16389119e-01],\n",
       "       [-2.12896089e-01,  6.16480189e-02,  1.40385531e-01,\n",
       "         4.98087431e-02],\n",
       "       [ 9.10316589e-04,  5.99601875e-02, -2.42326800e-01,\n",
       "        -2.59892614e-01],\n",
       "       [ 3.38673583e-01, -1.82156595e-01, -4.11265482e-01,\n",
       "         1.55827646e-01],\n",
       "       [-4.00863083e-02, -2.09998575e-02, -3.73304663e-01,\n",
       "         4.08937184e-01],\n",
       "       [ 2.62481138e-01, -4.71010301e-01,  4.35571983e-01,\n",
       "         2.17498071e-01],\n",
       "       [ 4.74617247e-01,  1.89618634e-01,  2.78057276e-01,\n",
       "         1.00578629e-01],\n",
       "       [ 1.73353841e-01, -1.20930110e-02, -2.47325315e-01,\n",
       "        -2.32611008e-01],\n",
       "       [-2.32107431e-01,  4.25352389e-01,  1.86908792e-01,\n",
       "         3.46683775e-01],\n",
       "       [-2.83328524e-01,  4.90982662e-01,  2.69992320e-01,\n",
       "        -3.11171166e-01],\n",
       "       [ 2.52693882e-01,  2.79334024e-02, -3.44472108e-02,\n",
       "        -2.44715533e-01],\n",
       "       [ 4.76111316e-01, -1.33794614e-01,  3.28386973e-01,\n",
       "        -3.59013841e-03],\n",
       "       [-1.86465244e-01, -3.63292411e-01,  3.30170144e-01,\n",
       "        -2.70746549e-02],\n",
       "       [ 2.55962523e-01,  4.05664440e-01,  4.29374344e-01,\n",
       "        -3.03377157e-01],\n",
       "       [ 4.06287477e-01,  4.45295130e-01,  4.84557531e-01,\n",
       "        -1.78035889e-01],\n",
       "       [ 1.35657291e-01,  4.58656115e-01,  1.82741731e-01,\n",
       "         4.34262773e-01],\n",
       "       [-3.62840666e-01,  5.84427423e-02, -8.38787457e-02,\n",
       "         2.40265189e-01],\n",
       "       [ 1.66845762e-01, -3.34187607e-01,  7.37296579e-02,\n",
       "        -3.38955570e-01],\n",
       "       [-2.26054550e-01, -1.16264170e-01,  1.76401440e-01,\n",
       "         9.75124918e-02],\n",
       "       [-9.59953774e-02, -1.46796528e-01, -3.34628111e-01,\n",
       "        -3.21797202e-01],\n",
       "       [-1.18950516e-01,  4.60990329e-02,  3.35953564e-01,\n",
       "         2.43571687e-01],\n",
       "       [ 1.85468882e-01,  4.32822494e-01,  3.85689144e-01,\n",
       "        -4.13709357e-01],\n",
       "       [ 2.19623003e-01,  5.32873368e-02,  1.11949168e-02,\n",
       "         5.47846674e-02],\n",
       "       [-4.90950664e-01,  4.58944964e-01, -2.72410103e-01,\n",
       "         1.63381987e-01],\n",
       "       [ 1.83943009e-01, -3.78476637e-01, -7.90153742e-03,\n",
       "         4.46058873e-01],\n",
       "       [-2.25968987e-01,  1.47905764e-01,  1.02844112e-01,\n",
       "        -2.90292227e-01],\n",
       "       [-2.61803992e-02,  6.12652031e-02, -2.93581995e-01,\n",
       "         3.13415910e-01],\n",
       "       [ 4.73605085e-01,  6.33338824e-02,  1.90660009e-01,\n",
       "        -1.30470398e-01],\n",
       "       [ 1.58750754e-01, -3.45825932e-01,  4.69421470e-01,\n",
       "         4.60018859e-01],\n",
       "       [-2.85828539e-01, -4.41583600e-01, -1.90688388e-02,\n",
       "        -4.45312511e-01],\n",
       "       [-5.85971690e-02, -2.99515869e-01, -1.04299959e-03,\n",
       "        -4.58745769e-01],\n",
       "       [ 9.49818978e-02,  2.14167318e-01,  1.36435650e-01,\n",
       "        -2.72538540e-01],\n",
       "       [ 1.74048669e-01, -1.84463685e-01, -1.64047517e-01,\n",
       "         1.92228748e-01],\n",
       "       [-1.62970267e-01,  4.48093105e-02,  3.57871816e-01,\n",
       "        -4.11533432e-01],\n",
       "       [ 5.24065852e-02,  2.08291426e-01,  1.55366695e-01,\n",
       "         4.78597179e-01],\n",
       "       [ 4.66535514e-01, -2.88899618e-01, -4.76689666e-01,\n",
       "         3.05958900e-01],\n",
       "       [-4.26025998e-01, -3.69670577e-01, -1.66207659e-01,\n",
       "         3.76042307e-01],\n",
       "       [ 3.75015271e-01,  1.24197649e-01, -4.44608817e-01,\n",
       "        -1.02697378e-01],\n",
       "       [ 8.95097740e-02,  2.32020274e-01, -8.07287397e-02,\n",
       "        -4.35055244e-01],\n",
       "       [-4.73630937e-01, -1.83087091e-01,  2.70108382e-01,\n",
       "         2.36005111e-01],\n",
       "       [-3.85885273e-01,  4.27010137e-02, -2.91035635e-01,\n",
       "         2.32517902e-01],\n",
       "       [-6.91532160e-03,  1.24380282e-01, -1.57102107e-01,\n",
       "        -4.32215406e-01],\n",
       "       [ 2.80524901e-01,  1.41891586e-01, -4.14032932e-01,\n",
       "        -1.67737396e-02],\n",
       "       [-2.71184929e-01, -3.31198670e-01, -4.82366271e-01,\n",
       "         1.97483343e-01],\n",
       "       [-3.74173969e-01,  1.82829024e-01,  3.88836149e-01,\n",
       "         3.71531540e-02],\n",
       "       [-1.60685782e-01,  2.18872768e-01,  2.42435257e-01,\n",
       "        -1.95082546e-01],\n",
       "       [-3.33632882e-01,  4.33607738e-01, -3.95899994e-01,\n",
       "         9.45533074e-02],\n",
       "       [ 1.36564426e-01,  2.98024013e-02, -1.05401642e-01,\n",
       "        -3.93381534e-03],\n",
       "       [-3.66439814e-01,  3.01075833e-01, -3.78376148e-01,\n",
       "        -3.18381864e-01],\n",
       "       [-3.77118682e-01,  4.81606815e-01, -2.29622614e-01,\n",
       "         3.16955139e-01],\n",
       "       [ 3.41101587e-01,  9.28846599e-02,  4.96180594e-01,\n",
       "        -4.55593088e-01],\n",
       "       [ 4.14121297e-01, -2.23167453e-01, -3.26974671e-02,\n",
       "         1.82239212e-01],\n",
       "       [-3.20439618e-01, -3.04144673e-01, -3.73272858e-02,\n",
       "         3.30838369e-01],\n",
       "       [ 2.45457543e-01,  1.96964387e-01, -1.44880196e-01,\n",
       "        -9.86394074e-02],\n",
       "       [-3.99240638e-01, -8.74781125e-02,  5.66375539e-02,\n",
       "        -3.02681638e-01],\n",
       "       [-4.51783591e-01, -3.78833948e-01, -2.01392802e-01,\n",
       "         1.20804335e-01],\n",
       "       [ 3.22327297e-01, -2.10499820e-01, -1.07341979e-01,\n",
       "        -3.08366048e-01],\n",
       "       [-7.84470290e-02, -2.33306690e-01, -4.57821300e-02,\n",
       "         4.16653470e-01],\n",
       "       [ 4.82502700e-01, -4.99317827e-01, -3.21200937e-01,\n",
       "         4.46253203e-01],\n",
       "       [ 2.30456733e-01, -6.49169309e-03,  2.52199517e-01,\n",
       "         4.78935752e-01],\n",
       "       [ 3.23420912e-01,  4.61697542e-05, -4.76789450e-01,\n",
       "        -8.21057377e-02],\n",
       "       [ 2.82923165e-01, -1.32387079e-01, -3.98696531e-01,\n",
       "         1.89953046e-03],\n",
       "       [ 3.25748113e-01, -3.83560618e-01,  2.96076220e-01,\n",
       "         2.37023461e-01],\n",
       "       [ 3.71223501e-01, -3.19561155e-02, -1.94970596e-01,\n",
       "         3.97267388e-01],\n",
       "       [ 5.29162790e-02,  4.78482731e-01, -1.08794866e-01,\n",
       "         1.06189399e-01],\n",
       "       [ 2.77821532e-01,  6.55268672e-02, -5.19989359e-02,\n",
       "        -1.16888766e-01],\n",
       "       [-1.17644254e-01, -4.14235168e-01, -3.23383787e-01,\n",
       "         9.76767544e-04],\n",
       "       [ 1.78466093e-01,  3.81198915e-01,  1.43217485e-01,\n",
       "         5.76283102e-02],\n",
       "       [-7.18987064e-02, -4.45506414e-01, -4.23585123e-01,\n",
       "         4.60515371e-01],\n",
       "       [-3.58003116e-01, -1.85602109e-01, -1.70327025e-01,\n",
       "        -3.33033804e-01],\n",
       "       [ 1.57210867e-01,  3.14883471e-01, -1.05054126e-01,\n",
       "         2.68940860e-01],\n",
       "       [ 4.91226187e-01, -3.77783875e-01, -1.91134242e-01,\n",
       "        -4.91611908e-01],\n",
       "       [ 4.13589792e-01, -2.83844696e-01,  3.87579652e-01,\n",
       "         4.18436415e-01],\n",
       "       [ 2.71753927e-01, -4.60004674e-01,  2.97132713e-01,\n",
       "         2.20065402e-01],\n",
       "       [-4.26192210e-01, -1.30226281e-01,  2.40408661e-01,\n",
       "        -4.38759798e-01],\n",
       "       [ 3.28244628e-01, -2.63930685e-01,  9.32884971e-03,\n",
       "         2.47384648e-01],\n",
       "       [-4.46083841e-01, -4.81414691e-01, -8.90053510e-02,\n",
       "         1.17296897e-01],\n",
       "       [ 2.77922629e-01, -2.39700448e-01, -4.88046852e-01,\n",
       "         1.30788756e-01],\n",
       "       [-2.20539345e-01, -2.47310392e-03,  4.93963319e-01,\n",
       "         6.39348386e-02],\n",
       "       [-2.40768147e-01, -4.53197097e-01, -2.29371887e-01,\n",
       "         3.89359079e-01],\n",
       "       [ 3.65168967e-02, -3.13030730e-01, -4.50318062e-02,\n",
       "         2.28027729e-01],\n",
       "       [ 1.82898328e-01, -5.71440668e-02, -4.71230325e-01,\n",
       "         1.56086160e-02],\n",
       "       [ 1.42400693e-01,  3.19041213e-01,  6.05698919e-02,\n",
       "        -1.49973422e-01],\n",
       "       [ 1.77297354e-01, -2.26180301e-02, -7.38130877e-02,\n",
       "        -1.92981312e-01],\n",
       "       [-1.56671485e-01,  8.41368024e-02,  1.23242845e-01,\n",
       "         1.25432529e-01],\n",
       "       [ 2.43405100e-01, -3.14403026e-01, -4.95548155e-01,\n",
       "         4.68785861e-01],\n",
       "       [ 4.71931388e-01, -4.40887699e-01,  2.43946562e-01,\n",
       "         2.08932003e-01],\n",
       "       [ 7.58111024e-02,  1.75162508e-01, -4.14235679e-01,\n",
       "         3.12504241e-01],\n",
       "       [ 3.22442971e-01,  2.50860024e-02,  4.76502454e-01,\n",
       "        -1.10824129e-01],\n",
       "       [ 4.37793419e-01,  1.32332354e-01,  8.89860727e-02,\n",
       "         2.83951128e-01],\n",
       "       [-1.36408062e-01, -4.15784601e-01, -3.02312895e-01,\n",
       "        -2.19364901e-01],\n",
       "       [-2.71808514e-01,  1.10944184e-01,  3.10300333e-01,\n",
       "        -9.09167841e-02],\n",
       "       [-4.03357669e-01, -1.71537565e-01, -7.52679610e-02,\n",
       "        -4.54887111e-01],\n",
       "       [ 4.66683178e-01,  4.82056522e-01, -3.12557521e-01,\n",
       "         3.14473181e-01],\n",
       "       [-8.41947318e-02,  1.41208444e-01,  4.20911234e-01,\n",
       "        -3.96814237e-01],\n",
       "       [ 2.87382352e-01, -3.04590335e-01, -1.85276555e-01,\n",
       "        -3.33995463e-01],\n",
       "       [-4.88476761e-01, -1.65750994e-01,  4.68239159e-01,\n",
       "         3.62331495e-01],\n",
       "       [ 2.10393351e-01, -2.64321194e-01, -1.26766331e-01,\n",
       "        -4.86646197e-01],\n",
       "       [ 3.38247584e-01,  3.13303999e-01, -1.27551298e-01,\n",
       "        -3.81701405e-01],\n",
       "       [-1.14056632e-01,  3.71783280e-01,  1.74244906e-02,\n",
       "        -4.96714259e-01],\n",
       "       [ 1.00496449e-01,  4.41033252e-01, -4.56741261e-01,\n",
       "         3.91252033e-01],\n",
       "       [-7.35084722e-02,  2.29675619e-01, -4.48826747e-01,\n",
       "         4.35920842e-01],\n",
       "       [ 4.38617581e-01,  4.33387797e-01, -4.15477698e-01,\n",
       "        -1.32445050e-01],\n",
       "       [-3.40683812e-01,  4.72125257e-01, -4.58433422e-02,\n",
       "         4.40541977e-01],\n",
       "       [-2.36399397e-02,  1.59957566e-01,  1.05985194e-01,\n",
       "        -1.13690101e-01],\n",
       "       [ 3.55739677e-01, -2.81481862e-01, -1.61027543e-01,\n",
       "         1.48009264e-01],\n",
       "       [ 4.94719343e-01,  4.42229821e-01,  3.02734756e-01,\n",
       "        -1.57266593e-02],\n",
       "       [-1.85968390e-01,  2.52527294e-02,  2.17875983e-01,\n",
       "        -8.99922804e-02],\n",
       "       [-4.85155404e-01,  1.03466353e-01, -1.83056467e-02,\n",
       "         3.18695228e-01],\n",
       "       [-4.76303422e-02,  4.52614690e-01, -3.82574502e-01,\n",
       "         2.70076497e-01],\n",
       "       [-1.46114215e-01,  8.38603915e-02,  2.01228660e-01,\n",
       "         2.30441184e-01],\n",
       "       [-3.23571205e-01,  3.59428943e-01, -1.19732348e-01,\n",
       "         1.57948922e-02],\n",
       "       [-1.65438843e-01,  3.14854857e-01,  4.34980811e-02,\n",
       "         3.29446518e-01],\n",
       "       [-1.78934159e-01,  2.22524137e-01,  4.85823395e-01,\n",
       "        -3.42976914e-01],\n",
       "       [-1.46433547e-01, -4.93423563e-02,  1.32014690e-01,\n",
       "         2.29044733e-01],\n",
       "       [-3.52348716e-01,  4.21618342e-02, -2.07232476e-01,\n",
       "        -4.80634087e-01],\n",
       "       [ 1.67806009e-01,  2.79548650e-02, -4.88741556e-01,\n",
       "         4.34039945e-01],\n",
       "       [-3.63622034e-01,  4.03793998e-01,  3.16505552e-01,\n",
       "        -3.93578283e-01],\n",
       "       [ 4.09945557e-02,  4.04633984e-01,  2.24810250e-01,\n",
       "        -3.84133206e-01],\n",
       "       [ 1.57102338e-01,  1.40736856e-01,  3.43111768e-01,\n",
       "         4.57095813e-01],\n",
       "       [ 5.28517084e-02, -2.65130818e-01, -4.29395127e-01,\n",
       "         6.22516636e-02],\n",
       "       [-3.57937888e-01,  1.50581956e-01, -3.82222269e-01,\n",
       "         1.92945122e-01],\n",
       "       [-4.86844495e-02, -3.22957198e-01, -2.57896952e-01,\n",
       "        -4.17634781e-01],\n",
       "       [-1.56358931e-01,  2.14408189e-01,  1.74780064e-01,\n",
       "         1.12315717e-02],\n",
       "       [ 4.49952372e-01,  1.43761311e-01,  1.15641445e-01,\n",
       "        -4.45069696e-01],\n",
       "       [ 2.46655967e-01, -2.34431319e-01, -2.50701795e-01,\n",
       "        -3.98125868e-01],\n",
       "       [-3.66633884e-01, -3.25418637e-01, -1.08392364e-01,\n",
       "        -3.95354571e-02],\n",
       "       [-4.52844224e-01,  9.61801261e-03,  1.86716557e-02,\n",
       "         9.92541347e-02],\n",
       "       [-3.91280520e-02,  2.30683610e-02,  1.03612066e-01,\n",
       "        -4.99114534e-01],\n",
       "       [-3.46922738e-01,  3.10381285e-02, -1.21871887e-01,\n",
       "         4.77138795e-01],\n",
       "       [-9.42115558e-02, -7.84465373e-03,  2.03326848e-01,\n",
       "         5.14744052e-02],\n",
       "       [ 3.76118007e-01,  1.75089782e-01,  7.50001265e-02,\n",
       "         3.75026008e-01],\n",
       "       [-8.47489624e-02,  3.87031042e-02,  3.95503410e-01,\n",
       "         2.05485515e-01],\n",
       "       [-8.18833879e-02,  9.42489326e-02, -1.51131404e-01,\n",
       "        -1.19560440e-02],\n",
       "       [ 3.81708601e-01,  4.73085394e-02, -1.93918105e-01,\n",
       "         4.71302703e-01],\n",
       "       [-3.31624147e-01,  5.90029337e-02, -4.90555863e-01,\n",
       "        -4.95026862e-01],\n",
       "       [-3.57905086e-01, -4.14834573e-01,  2.46167555e-02,\n",
       "         5.58429477e-02],\n",
       "       [-4.36937136e-01, -2.11984373e-02,  1.92649433e-01,\n",
       "        -4.91680522e-02],\n",
       "       [ 2.76031821e-02, -2.89057420e-01, -4.01103995e-01,\n",
       "         3.85187113e-01],\n",
       "       [ 1.75796493e-01, -3.50788193e-01,  2.38300934e-01,\n",
       "         1.92063985e-01],\n",
       "       [-3.48259387e-01,  3.64298736e-01, -4.89768754e-01,\n",
       "         3.66609032e-01],\n",
       "       [-3.44177750e-01,  1.21132602e-01, -9.97751977e-02,\n",
       "         9.32688173e-02],\n",
       "       [-3.80358575e-01, -2.24552686e-01,  3.72695455e-01,\n",
       "         6.68162824e-02]])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP:\n",
    "    def __init__(self, epochs, learning_rate, input_layer,hidden_layer,output_layer, reg_param = 0,m=4):\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.input_layer = input_layer\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self.output_layer = output_layer\n",
    "        self.reg_param = reg_param \n",
    "        self.m = m\n",
    "        self.W1 = np.random.normal(0,1,(hidden_layer,input_layer))\n",
    "        self.W2 = np.random.normal(0,1,(output_layer,hidden_layer))\n",
    "        self.B1 = np.random.random((hidden_layer, 1)) # 2x1\n",
    "        self.B2 = np.random.random((output_layer, 1)) # 1x1\n",
    "        self.cost = np.zeros((self.epochs, 1))\n",
    "\n",
    "    \n",
    "    #Activation function\n",
    "    def sigmoid(self, z, derv=False):\n",
    "        if derv: return z * (1 - z)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    def forward(self, x, predict=False):\n",
    "        a1 = x.reshape(x.shape[0], 1) # Getting the training example as a column vector.\n",
    "\n",
    "        z2 = self.W1.dot(a1) + self.B1 # 2x2 * 2x1 + 2x1 = 2x1\n",
    "        a2 = self.sigmoid(z2) # 2x1\n",
    "\n",
    "        z3 = self.W2.dot(a2) + self.B2 # 1x2 * 2x1 + 1x1 = 1x1\n",
    "        a3 = sigmoid(z3)\n",
    "\n",
    "        if predict: return a3\n",
    "        return (a1, a2, a3)\n",
    "    def train(self): # The arguments are to bypass UnboundLocalError error\n",
    "        for i in range(self.epochs):\n",
    "            c = 0\n",
    "            \n",
    "        \n",
    "            dW1 = 0\n",
    "            dW2 = 0\n",
    "\n",
    "            dB1 = 0\n",
    "            dB2 = 0\n",
    "        \n",
    "            for j in range(self.m):\n",
    "                print(\"\\rIteration: {} and {}\".format(i + 1, j + 1))\n",
    "\n",
    "            # Forward Prop.\n",
    "                a0 = X[j].reshape(X[j].shape[0], 1) # 2x1\n",
    "\n",
    "                z1 = self.W1.dot(a0) + self.B1 # 2x2 * 2x1 + 2x1 = 2x1\n",
    "                a1 = self.sigmoid(z1) # 2x1\n",
    "\n",
    "                z2 = self.W2.dot(a1) + self.B2 # 1x2 * 2x1 + 1x1 = 1x1\n",
    "                a2 = self.sigmoid(z2) # 1x1\n",
    "\n",
    "                # Back prop.\n",
    "                dz2 = a2 - y[j] # 1x1\n",
    "                dW2 += dz2 * a1.T # 1x1 .* 1x2 = 1x2\n",
    "\n",
    "                dz1 = np.multiply((self.W2.T * dz2), self.sigmoid(a1, derv=True)) # (2x1 * 1x1) .* 2x1 = 2x1\n",
    "                dW1 += dz1.dot(a0.T) # 2x1 * 1x2 = 2x2\n",
    "\n",
    "                dB1 += dz1 # 2x1\n",
    "                dB2 += dz2 # 1x1\n",
    "\n",
    "                c = c + (-(y[j] * np.log(a2)) - ((1 - y[j]) * np.log(1 - a2)))\n",
    "            sys.stdout.flush() # Updating the text.\n",
    "            \n",
    "            self.W1 = self.W1 - self.learning_rate * (dW1 / self.m) + ( (self.reg_param / self.m) * self.W1)\n",
    "            self.W2 = self.W2 - self.learning_rate * (dW2 / self.m) + ( (self.reg_param / self.m) * self.W2)\n",
    "\n",
    "            self.B1 = self.B1 - self.learning_rate * (dB1 / self.m)\n",
    "            self.B2 = self.B2 - self.learning_rate * (dB2 / self.m)\n",
    "            self.cost[i] = (c / self.m) + ( \n",
    "            (self.reg_param / (2 * self.m)) * \n",
    "            (\n",
    "                np.sum(np.power(self.W1, 2)) + \n",
    "                np.sum(np.power(self.W2, 2))\n",
    "            )\n",
    "            )\n",
    "        return (self.W1, self.W2, self.B1, self.B2)\n",
    "    def predict(self):\n",
    "        # Assigning the axes to the different elements.\n",
    "        plt.plot(range(self.epochs),self. cost)\n",
    "\n",
    "        # Labelling the x axis as the iterations axis.\n",
    "        plt.xlabel(\"Iterations\")\n",
    "\n",
    "    # Labelling the y axis as the cost axis.\n",
    "        plt.ylabel(\"Cost\")\n",
    "\n",
    "        # Showing the plot.\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecb551c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
